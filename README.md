# Network-Aware Token Scheduling for LLM Streaming: System Design and Experimental Evaluation

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª**ç½‘ç»œæ„ŸçŸ¥çš„ LLM Token è°ƒåº¦ç³»ç»Ÿ**ï¼Œé€šè¿‡åœ¨ vLLM ä¸­é›†æˆç½‘ç»œçŠ¶æ€æ„ŸçŸ¥èƒ½åŠ›ï¼Œä¼˜å…ˆè°ƒåº¦ç½‘ç»œæ¡ä»¶è‰¯å¥½çš„ç”¨æˆ·è¯·æ±‚ï¼Œä»è€Œæå‡æ•´ä½“ç³»ç»Ÿçš„æœ‰æ•ˆååé‡ï¼ˆEffective Throughputï¼‰ã€‚ç³»ç»ŸåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

1. **vLLM è°ƒåº¦å™¨ä¿®æ”¹**ï¼šåœ¨ vLLM å¼•æ“ä¸­é›†æˆ Network-Aware è°ƒåº¦é€»è¾‘
2. **Open WebUI å‰ç«¯æ”¹é€ **ï¼šå®æ—¶æµ‹é‡ RTT å¹¶é€šè¿‡è¯·æ±‚æ³¨å…¥å¥åº·åº¦å‚æ•°
3. **å®éªŒéªŒè¯æ¡†æ¶**ï¼šé€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯ Network-Aware è°ƒåº¦çš„ä¼˜åŠ¿

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Open WebUI (Modified)                                   â”‚  â”‚
â”‚  â”‚  - RTT Measurement (æ¯ 2 ç§’)                              â”‚  â”‚
â”‚  â”‚  - Fetch Interception (è‡ªåŠ¨æ³¨å…¥ X-Client-RTT header)     â”‚  â”‚
â”‚  â”‚  - UI Display (å®æ—¶æ˜¾ç¤ºç½‘ç»œçŠ¶æ€)                          â”‚  â”‚
â”‚  â”‚  - WiFi Button (ç”¨æˆ·å¯æ§çš„ç½‘ç»œä¼˜åŒ–å¼€å…³)                    â”‚  â”‚
â”‚  â”‚  - Network Mode Store (å…¨å±€çŠ¶æ€ç®¡ç†)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP Request
                             â”‚ + X-Client-RTT header
                             â”‚ + params.network_aware (WiFiæŒ‰é’®)
                             â”‚ + vllm_xargs.health_factor
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Backend Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Open WebUI Backend (Modified)                           â”‚  â”‚
â”‚  â”‚  - æå– X-Client-RTT header                              â”‚  â”‚
â”‚  â”‚  - è®¡ç®— health_factor = exp(-RTT / 500)                  â”‚  â”‚
â”‚  â”‚  - æ³¨å…¥åˆ° vllm_xargs.health_factor                        â”‚  â”‚
â”‚  â”‚  - é™æ€ System Prompt æ³¨å…¥ (KV Cache å‹å¥½)                â”‚  â”‚
â”‚  â”‚  - åŠ¨æ€ User Prompt RTT æ³¨å…¥                              â”‚  â”‚
â”‚  â”‚  - åŠ¨æ€ Chunk Size è°ƒæ•´ (æ ¹æ® RTT)                        â”‚  â”‚
â”‚  â”‚  - åº”ç”¨å±‚ Nagle ç®—æ³• (network_chunk_wrapper)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Forward Request
                             â”‚ + health_factor in vllm_xargs
                             â”‚ + Modified Messages (Promptæ³¨å…¥)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    vLLM Engine (Modified)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  EngineCore.add_request()                                 â”‚  â”‚
â”‚  â”‚  - ä» extra_args æå– health_factor                        â”‚  â”‚
â”‚  â”‚  - è®¾ç½® request.health_factor                              â”‚  â”‚
â”‚  â”‚  - ä¼ é€’ç»™ Scheduler                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Priority Scheduler                                       â”‚  â”‚
â”‚  â”‚  - æ ¹æ® health_factor è°ƒæ•´è¯·æ±‚ä¼˜å…ˆçº§                       â”‚  â”‚
â”‚  â”‚  - ç½‘ç»œå¥½ç”¨æˆ·ä¼˜å…ˆè°ƒåº¦                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Streaming Response
                             â”‚ (SSE chunks)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Transport Layer Optimization                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  network_chunk_wrapper()                                  â”‚  â”‚
â”‚  â”‚  - æ‹¦æˆª SSE æµ                                            â”‚  â”‚
â”‚  â”‚  - ç§¯æ”’å¤šä¸ª chunk åˆå¹¶æˆ TCP åŒ…                            â”‚  â”‚
â”‚  â”‚  - å‡å°‘å¼±ç½‘ç¯å¢ƒä¸‹çš„ TCP åŒ…æ•°é‡                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Optimized TCP Packets
                             â–¼
                         Client (æµè§ˆå™¨)
```

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. vLLM å¼•æ“ä¿®æ”¹

**ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨**ï¼š
- `vllm/vllm/v1/engine/core.py` - å¼•æ“æ ¸å¿ƒï¼Œæ·»åŠ å¥åº·åº¦æå–é€»è¾‘
- `vllm/vllm/v1/core/sched/scheduler.py` - è°ƒåº¦å™¨ï¼Œæ”¯æŒåŸºäºå¥åº·åº¦çš„ä¼˜å…ˆçº§è°ƒåº¦
- `vllm/vllm/v1/request.py` - è¯·æ±‚å¯¹è±¡ï¼Œæ·»åŠ  health_factor å­—æ®µ

---

#### 1.1 Request å¯¹è±¡ä¿®æ”¹ (`vllm/vllm/v1/request.py`)

**ä¿®æ”¹ä½ç½®**ï¼šç¬¬ 140-154 è¡Œã€ç¬¬ 179-191 è¡Œ

##### 1.1.1 æ·»åŠ  health_factor å­—æ®µï¼ˆ140-143è¡Œï¼‰

åœ¨ `Request` ç±»çš„ `__init__` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
# --- [NETWORK-AWARE SCHEDULING MODIFICATION START] ---
# Per-request health factor (0.0 - 1.0)
# æ¯ä¸ªè¯·æ±‚ç‹¬ç«‹çš„å¥åº·åº¦ï¼Œç”¨äº per-user ç®—åŠ›åˆ†é…
self.health_factor: float = 1.0
# --- [NETWORK-AWARE SCHEDULING MODIFICATION END] ---
```

**ä½œç”¨**ï¼šä¸ºæ¯ä¸ªè¯·æ±‚å¯¹è±¡æ·»åŠ ç‹¬ç«‹çš„å¥åº·åº¦å­—æ®µï¼Œé»˜è®¤å€¼ä¸º 1.0ï¼ˆbaseline æ¨¡å¼ï¼‰ã€‚

##### 1.1.2 ä» extra_args æå– health_factorï¼ˆ179-191è¡Œï¼‰

åœ¨ `from_engine_core_request()` ç±»æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
# ä» extra_args ä¸­æå– health_factorï¼ˆå¦‚æœæä¾›ï¼‰
if request.sampling_params and hasattr(request.sampling_params, 'extra_args'):
    extra_args = request.sampling_params.extra_args
    if extra_args and isinstance(extra_args, dict):
        health_factor = extra_args.get("health_factor")
        if health_factor is not None:
            try:
                req.health_factor = float(health_factor)
            except (ValueError, TypeError):
                req.health_factor = 1.0  # ä½¿ç”¨é»˜è®¤å€¼
```

**ä½œç”¨**ï¼šåœ¨åˆ›å»º Request å¯¹è±¡æ—¶ï¼Œå¦‚æœå®¢æˆ·ç«¯é€šè¿‡ `vllm_xargs` ä¼ é€’äº† `health_factor`ï¼Œåˆ™è‡ªåŠ¨æå–å¹¶è®¾ç½®ã€‚

##### 1.1.3 ä¿®æ”¹è¯·æ±‚æ¯”è¾ƒé€»è¾‘ï¼ˆ295-310è¡Œï¼‰

ä¿®æ”¹ `__lt__` æ–¹æ³•ï¼Œæ”¯æŒåŸºäº health_factor çš„ä¼˜å…ˆçº§æ¯”è¾ƒï¼š

```python
def __lt__(self, other: "Request") -> bool:
    # é¦–å…ˆæ¯”è¾ƒ priorityï¼ˆå¦‚æœä¸åŒï¼‰
    if self.priority != other.priority:
        return self.priority > other.priority  # é«˜ä¼˜å…ˆçº§ä¼˜å…ˆ
    
    # ç„¶åæ¯”è¾ƒ health_factorï¼ˆé«˜å¥åº·åº¦ä¼˜å…ˆï¼‰
    if abs(self.health_factor - other.health_factor) > 0.01:
        return self.health_factor > other.health_factor
    
    # æœ€åæ¯”è¾ƒåˆ°è¾¾æ—¶é—´ï¼ˆæ—©åˆ°çš„ä¼˜å…ˆï¼‰
    return self.arrival_time < other.arrival_time
```

**ä½œç”¨**ï¼šåœ¨ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸­ï¼Œç›¸åŒä¼˜å…ˆçº§çš„è¯·æ±‚ä¼šæŒ‰ç…§ health_factor æ’åºï¼Œç½‘ç»œå¥½çš„ç”¨æˆ·è¯·æ±‚ä¼˜å…ˆè¢«è°ƒåº¦ã€‚

---

#### 1.2 EngineCore ä¿®æ”¹ (`vllm/vllm/v1/engine/core.py`)

**ä¿®æ”¹ä½ç½®**ï¼šç¬¬ 394-476 è¡Œ

##### 1.2.1 add_request() æ–¹æ³•ä¸­çš„å¥åº·åº¦æå–ï¼ˆ425-474è¡Œï¼‰

åœ¨ `EngineCore.add_request()` æ–¹æ³•ä¸­æ·»åŠ äº†å®Œæ•´çš„ Network-Aware è°ƒåº¦é€»è¾‘ï¼š

```python
# --- [NETWORK-AWARE SCHEDULING] ---
health_from_request = False

# æ£€æŸ¥ extra_args ä¸­æ˜¯å¦æœ‰ health_factorï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
if request.sampling_params and hasattr(request.sampling_params, 'extra_args'):
    extra_args = request.sampling_params.extra_args
    if extra_args and isinstance(extra_args, dict) and "health_factor" in extra_args:
        health_from_request = True
        try:
            health_val = float(extra_args["health_factor"])
            request.health_factor = health_val
            logger.info(f"[NETWORK-AWARE] Request {request.request_id[:20]}... health={health_val:.3f} (from vllm_xargs)")
        except (ValueError, TypeError) as e:
            logger.warning(f"[NETWORK-AWARE] Failed to parse health_factor: {e}")
            health_from_request = False

if not health_from_request:
    # è¯·æ±‚ä¸­æ²¡æœ‰æä¾› health_factorï¼Œä» Hint Server è·å–ï¼ˆfallbackï¼‰
    user_id = self._extract_user_id(request.request_id)
    if user_id == 0:
        user_id = hash(request.request_id) % 10000 + 1
    
    with self.per_user_health_lock:
        if user_id in self.per_user_health:
            request.health_factor = self.per_user_health[user_id]
        else:
            # æŸ¥è¯¢ Hint Serverï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼‰
            health = 1.0
            try:
                import requests as http_requests
                resp = http_requests.get(f"{self.hint_url}?user_id={user_id}", timeout=0.05)
                if resp.status_code == 200:
                    data = resp.json()
                    health = data.get("health", 1.0)
            except Exception:
                pass
            self.per_user_health[user_id] = health
            request.health_factor = health
# --- [END NETWORK-AWARE SCHEDULING] ---
```

**å…³é”®è®¾è®¡**ï¼š
1. **ä¼˜å…ˆçº§æœºåˆ¶**ï¼šä¼˜å…ˆä½¿ç”¨è¯·æ±‚ä¸­ç›´æ¥ä¼ é€’çš„ `health_factor`ï¼ˆé€šè¿‡ `vllm_xargs`ï¼‰
2. **Fallback æœºåˆ¶**ï¼šå¦‚æœæ²¡æœ‰æä¾›ï¼Œåˆ™ä» Hint Server è·å–ï¼ˆæ”¯æŒæ—§ç‰ˆå®¢æˆ·ç«¯ï¼‰
3. **ç¼“å­˜æœºåˆ¶**ï¼šä½¿ç”¨ `per_user_health` å­—å…¸ç¼“å­˜æ¯ä¸ªç”¨æˆ·çš„å¥åº·åº¦ï¼Œé¿å…é‡å¤æŸ¥è¯¢
4. **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨ `per_user_health_lock` ä¿æŠ¤å…±äº«æ•°æ®

##### 1.2.2 ç”¨æˆ· ID æå–æ–¹æ³•ï¼ˆ328-341è¡Œï¼‰

æ·»åŠ äº† `_extract_user_id()` è¾…åŠ©æ–¹æ³•ï¼š

```python
def _extract_user_id(self, request_id: str) -> int:
    """ä» request_id ä¸­æå– user_id
    
    æ”¯æŒå¤šç§æ ¼å¼:
    - 'user{N}_xxx' -> N
    - 'chatcmpl-user{N}_xxx' -> N (vLLM ä¼šæ·»åŠ  chatcmpl- å‰ç¼€)
    - å…¶ä»–æ ¼å¼ -> 0
    """
    import re
    match = re.search(r'user(\d+)_', request_id)
    if match:
        return int(match.group(1))
    return 0
```

**ä½œç”¨**ï¼šä»è¯·æ±‚ ID ä¸­æå–ç”¨æˆ· IDï¼Œç”¨äºæŸ¥è¯¢ Hint Server æˆ–ä½¿ç”¨ç¼“å­˜ã€‚

---

#### 1.3 Scheduler ä¿®æ”¹ (`vllm/vllm/v1/core/sched/scheduler.py`)

**ä¿®æ”¹ä½ç½®**ï¼šç¬¬ 105 è¡Œã€ç¬¬ 214-216 è¡Œã€ç¬¬ 270-285 è¡Œã€ç¬¬ 399 è¡Œ

##### 1.3.1 æ·»åŠ å…¨å±€ health_factorï¼ˆ105è¡Œï¼‰

åœ¨ `Scheduler.__init__()` ä¸­ï¼š

```python
# Network-aware pacing factor (0.0 to 1.0)
self.health_factor = 1.0
```

**ä½œç”¨**ï¼šè°ƒåº¦å™¨çº§åˆ«çš„å…¨å±€å¥åº·åº¦å› å­ï¼ˆç”¨äºå…¨å±€æµæ§ï¼Œå½“å‰ç‰ˆæœ¬ä¸»è¦ä½¿ç”¨ per-request çš„ health_factorï¼‰ã€‚

##### 1.3.2 set_health_factor() æ–¹æ³•ï¼ˆ214-216è¡Œï¼‰

```python
def set_health_factor(self, factor: float):
    """Update the health factor for network-aware pacing."""
    self.health_factor = max(0.01, min(1.0, factor))
```

**ä½œç”¨**ï¼šå…è®¸å¤–éƒ¨ï¼ˆå¦‚ Hint Serverï¼‰åŠ¨æ€æ›´æ–°å…¨å±€å¥åº·åº¦å› å­ã€‚

##### 1.3.3 schedule() æ–¹æ³•ä¸­çš„æ’åºé€»è¾‘ï¼ˆ270-285è¡Œï¼‰

åœ¨æ¯æ¬¡è°ƒåº¦æ—¶ï¼Œå¯¹ running å’Œ waiting é˜Ÿåˆ—æŒ‰ health_factor æ’åºï¼š

```python
# --- [NETWORK-AWARE SCHEDULING] ---
# GPU ååé‡ä¸å˜ï¼Œä½†ä¼˜å…ˆè°ƒåº¦é«˜å¥åº·åº¦çš„è¯·æ±‚
# é«˜å¥åº·åº¦è¯·æ±‚æ›´æ—©è¿›å…¥ runningï¼Œæ›´æ—©å®Œæˆ
# ä½å¥åº·åº¦è¯·æ±‚ç­‰å¾…ï¼Œå‡å°‘æµªè´¹

# 1. å¯¹ running é˜Ÿåˆ—æŒ‰å¥åº·åº¦æ’åº
if self.running:
    self.running.sort(key=lambda r: -r.health_factor)

# 2. å¯¹ waiting é˜Ÿåˆ—é‡æ–°æ’åºï¼ˆåŸºäº health_factorï¼‰
#    vLLM ä½¿ç”¨ heapqï¼Œéœ€è¦é‡æ–°æ„å»ºå †
if hasattr(self.waiting, '_heap') and self.waiting:
    import heapq
    heapq.heapify(self.waiting._heap)
# --- [END NETWORK-AWARE SCHEDULING] ---
```

**å…³é”®æœºåˆ¶**ï¼š
1. **Running é˜Ÿåˆ—æ’åº**ï¼šæ­£åœ¨è¿è¡Œçš„è¯·æ±‚æŒ‰ health_factor é™åºæ’åˆ—ï¼Œé«˜å¥åº·åº¦è¯·æ±‚ä¼˜å…ˆå¤„ç†
2. **Waiting é˜Ÿåˆ—é‡æ’**ï¼šä½¿ç”¨ `heapq.heapify()` é‡æ–°æ„å»ºå †ï¼Œç¡®ä¿é«˜å¥åº·åº¦è¯·æ±‚åœ¨å †é¡¶

##### 1.3.4 æŠ¢å é€»è¾‘ä¸­çš„ health_factorï¼ˆ399è¡Œï¼‰

åœ¨ä¼˜å…ˆçº§æŠ¢å æ—¶ï¼Œè€ƒè™‘ health_factorï¼š

```python
if self.policy == SchedulingPolicy.PRIORITY:
    preempted_req = max(
        self.running,
        key=lambda r: (r.priority, -r.health_factor, r.arrival_time),
    )
```

**ä½œç”¨**ï¼šå½“éœ€è¦æŠ¢å æ—¶ï¼Œä¼˜å…ˆæŠ¢å ä½å¥åº·åº¦çš„è¯·æ±‚ï¼ˆåœ¨ç›¸åŒä¼˜å…ˆçº§ä¸‹ï¼‰ã€‚

---

#### 1.4 å¥åº·åº¦è®¡ç®—

å¥åº·åº¦è®¡ç®—å…¬å¼ï¼š
```
health_factor = exp(-RTT / 500.0)
```

**æ˜ å°„å…³ç³»**ï¼š
- **RTT < 100ms**ï¼šhealth_factor â‰ˆ 0.82ï¼ˆç½‘ç»œæå¥½ï¼‰
- **RTT = 200ms**ï¼šhealth_factor â‰ˆ 0.67ï¼ˆç½‘ç»œè‰¯å¥½ï¼‰
- **RTT = 500ms**ï¼šhealth_factor â‰ˆ 0.37ï¼ˆç½‘ç»œè¾ƒå·®ï¼‰
- **RTT > 1000ms**ï¼šhealth_factor < 0.14ï¼ˆç½‘ç»œæå·®ï¼‰

**è®¾è®¡åŸç†**ï¼š
- ä½¿ç”¨æŒ‡æ•°è¡°å‡å‡½æ•°ï¼Œç¡®ä¿ RTT è¶Šå¤§ï¼Œhealth_factor è¶Šå°
- åˆ†æ¯ 500 æ˜¯ä¸€ä¸ªè°ƒä¼˜å‚æ•°ï¼Œæ§åˆ¶è¡°å‡é€Ÿåº¦
- health_factor èŒƒå›´ [0.0, 1.0]ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºç½‘ç»œè¶Šå¥½

---

#### 1.5 æ•°æ®æµå›¾

```
å®¢æˆ·ç«¯è¯·æ±‚
    â†“
Open WebUI Backend
    â†“ (è®¡ç®— health_factor = exp(-RTT/500))
    â†“ (æ³¨å…¥åˆ° vllm_xargs.health_factor)
    â†“
vLLM EngineCore.add_request()
    â†“ (ä» extra_args æå– health_factor)
    â†“ (è®¾ç½® request.health_factor)
    â†“
Request å¯¹è±¡åˆ›å»º
    â†“ (health_factor å­—æ®µå·²è®¾ç½®)
    â†“
Scheduler.add_request()
    â†“ (åŠ å…¥ waiting é˜Ÿåˆ—)
    â†“
Scheduler.schedule()
    â†“ (æŒ‰ health_factor æ’åº)
    â†“ (é«˜ health_factor è¯·æ±‚ä¼˜å…ˆè¿›å…¥ running)
    â†“
GPU æ‰§è¡Œï¼ˆä¼˜å…ˆå¤„ç†ç½‘ç»œå¥½çš„ç”¨æˆ·ï¼‰
```

---

#### 1.6 å…³é”®è®¾è®¡å†³ç­–

1. **Per-Request Health Factor**ï¼šæ¯ä¸ªè¯·æ±‚ç‹¬ç«‹çš„å¥åº·åº¦ï¼Œè€Œä¸æ˜¯å…¨å±€ç»Ÿä¸€å€¼
2. **åŒé‡æå–æœºåˆ¶**ï¼šæ—¢æ”¯æŒä» `extra_args` æå–ï¼Œä¹Ÿæ”¯æŒä» Hint Server è·å–
3. **ç¼“å­˜ä¼˜åŒ–**ï¼šä½¿ç”¨å­—å…¸ç¼“å­˜ç”¨æˆ·å¥åº·åº¦ï¼Œé¿å…é‡å¤æŸ¥è¯¢
4. **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®ç»“æ„
5. **å‘åå…¼å®¹**ï¼šå¦‚æœæ²¡æœ‰æä¾› health_factorï¼Œé»˜è®¤ä½¿ç”¨ 1.0ï¼ˆbaseline è¡Œä¸ºï¼‰

---

### 2. Open WebUI å‰ç«¯ä¿®æ”¹

**æ–‡ä»¶ä½ç½®**ï¼š`my-open-webui/src/routes/+layout.svelte`

#### 2.1 RTT æµ‹é€Ÿæ¨¡å—ï¼ˆ604-638è¡Œï¼‰

```javascript
// RTT æµ‹é€Ÿé€»è¾‘
async function measureRTT() {
    const start = performance.now();
    try {
        await fetch('/api/version', {cache: "no-store"});
        const end = performance.now();
        const current = Math.round(end - start);
        window._currentRTT = current;
        
        // æ›´æ–° UI å˜é‡
        rtt = current;
        if (rtt < 100) rttColor = 'text-green-500';      // æå¥½
        else if (rtt < 300) rttColor = 'text-yellow-500'; // ä¸€èˆ¬
        else rttColor = 'text-red-500';                  // å·®
    } catch (e) {
        // ignore
    }
}

// åŠ«æŒ fetchï¼Œè‡ªåŠ¨æ³¨å…¥ RTT
const originalFetch = window.fetch;
window.fetch = async function(url, options) {
    if (url && url.toString().includes('/chat/completions')) {
        options = options || {};
        options.headers = options.headers || {};
        options.headers['X-Client-RTT'] = window._currentRTT.toString();
    }
    return originalFetch(url, options);
};

// æ¯ 2 ç§’æµ‹é‡ä¸€æ¬¡
measureRTT();
const rttInterval = setInterval(measureRTT, 2000);
```

**åŠŸèƒ½ç‰¹ç‚¹**ï¼š
- æ¯ 2 ç§’è‡ªåŠ¨æµ‹é‡ä¸€æ¬¡ RTTï¼ˆé€šè¿‡ `/api/version` æ¥å£ï¼‰
- è‡ªåŠ¨æ‹¦æˆªæ‰€æœ‰å‘å¾€ `/chat/completions` çš„è¯·æ±‚
- åœ¨è¯·æ±‚ header ä¸­æ³¨å…¥ `X-Client-RTT`
- å®æ—¶æ›´æ–° UI æ˜¾ç¤ºï¼ˆå³ä¸‹è§’æ‚¬æµ®çª—å£ï¼‰

#### 2.2 UI æ˜¾ç¤ºç»„ä»¶ï¼ˆ927-937è¡Œï¼‰

åœ¨å±å¹•å³ä¸‹è§’æ˜¾ç¤ºå®æ—¶ç½‘ç»œçŠ¶æ€ï¼š

```svelte
<div class="fixed bottom-4 right-4 z-50 flex items-center gap-2 px-3 py-2 bg-gray-900/80 backdrop-blur rounded-lg border border-gray-700 shadow-lg select-none">
    <div class="text-xs font-mono text-gray-400">NETWORK RTT</div>
    <div class="text-sm font-bold font-mono {rttColor}">
        {rtt} ms
    </div>
    <!-- åŠ¨æ€ä¿¡å·æ ¼å›¾æ ‡ -->
    <div class="flex items-end gap-0.5 h-3">
        <div class="w-1 bg-current {rtt < 500 ? rttColor : 'text-gray-600'} h-1 rounded-sm"></div>
        <div class="w-1 bg-current {rtt < 300 ? rttColor : 'text-gray-600'} h-2 rounded-sm"></div>
        <div class="w-1 bg-current {rtt < 100 ? rttColor : 'text-gray-600'} h-3 rounded-sm"></div>
    </div>
</div>
```

---

### 3. Open WebUI åç«¯ä¿®æ”¹

**æ–‡ä»¶ä½ç½®**ï¼š`my-open-webui/backend/open_webui/main.py`

#### 3.1 RTT å¤„ç†é€»è¾‘ï¼ˆ1529-1540è¡Œï¼‰

åœ¨ `chat_completion()` å‡½æ•°ä¸­æ·»åŠ ï¼š

```python
# === Network-Aware Logic ===
import math
try:
    rtt = float(request.headers.get("X-Client-RTT", "100"))
    health = math.exp(-rtt / 500.0)
    health = max(0.0, min(1.0, health))
except:
    health = 1.0

if "vllm_xargs" not in form_data:
    form_data["vllm_xargs"] = {}
form_data["vllm_xargs"]["health_factor"] = health
# ===========================
```

**å¤„ç†æµç¨‹**ï¼š
1. ä»è¯·æ±‚ header ä¸­æå– `X-Client-RTT`
2. ä½¿ç”¨å…¬å¼ `health = exp(-RTT / 500.0)` è®¡ç®—å¥åº·åº¦
3. å°† `health_factor` æ³¨å…¥åˆ° `form_data["vllm_xargs"]` ä¸­
4. è½¬å‘ç»™ vLLM æ—¶ï¼ŒvLLM ä¼šè‡ªåŠ¨æå–å¹¶ä½¿ç”¨è¯¥å‚æ•°

---

#### 3.2 ç½‘ç»œä¼˜åŒ–å¢å¼ºåŠŸèƒ½ï¼ˆ1710-1884è¡Œï¼‰

åœ¨ `process_chat()` å‡½æ•°ä¸­å®ç°äº†å®Œæ•´çš„ç½‘ç»œä¼˜åŒ–é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š

##### 3.2.1 åº”ç”¨å±‚ Nagle ç®—æ³•ï¼ˆ1711-1751è¡Œï¼‰

å®ç°äº† `network_chunk_wrapper()` å‡½æ•°ï¼Œç”¨äºåœ¨åº”ç”¨å±‚å¯¹ SSE æµè¿›è¡Œæ‰“åŒ…ï¼š

```python
async def network_chunk_wrapper(original_iterator, chunk_size):
    """
    åº”ç”¨å±‚ Nagle ç®—æ³•çš„æ ¸å¿ƒå®ç°ã€‚
    æ‹¦æˆªåŸå§‹çš„ SSE æµï¼Œç§¯æ”’ chunk_size ä¸ªæ•°æ®åŒ…åï¼Œåˆå¹¶æˆä¸€ä¸ª TCP åŒ…å‘å‡ºã€‚
    """
    buffer = b""
    count = 0
    min_buffer_size = max(8192, chunk_size * 500)  # åŠ¨æ€è°ƒæ•´æœ€å°ç¼“å†²åŒº
    
    try:
        async for chunk in original_iterator:
            buffer += chunk
            count += 1
            
            # åŒé‡æ¡ä»¶ï¼šè¾¾åˆ°åŒ…æ•°é‡ OR è¾¾åˆ°æœ€å°ç¼“å†²åŒºå¤§å°
            if count >= chunk_size:
                yield buffer
                buffer = b""
                count = 0
            elif len(buffer) >= min_buffer_size and chunk_size > 5:
                yield buffer
                buffer = b""
                count = 0
        
        # å¾ªç¯ç»“æŸåï¼Œå¦‚æœè¿˜æœ‰æ®‹ç•™çš„ï¼Œä¸€æ¬¡æ€§å‘å‡º
        if buffer:
            yield buffer
    except Exception as e:
        if buffer:
            yield buffer
        raise e
```

**è®¾è®¡åŸç†**ï¼š
- **å‡å°‘ TCP åŒ…æ•°é‡**ï¼šåœ¨å¼±ç½‘ç¯å¢ƒä¸‹ï¼Œé€šè¿‡ç§¯æ”’å¤šä¸ª SSE chunk å‡å°‘ TCP åŒ…æ•°é‡ï¼Œé™ä½ç½‘ç»œå¼€é”€
- **åŠ¨æ€ç¼“å†²åŒº**ï¼šæ ¹æ®ç½‘ç»œçŠ¶å†µåŠ¨æ€è°ƒæ•´æœ€å°ç¼“å†²åŒºå¤§å°ï¼Œé¿å…è¿‡åº¦ç­‰å¾…
- **åŒé‡è§¦å‘æ¡ä»¶**ï¼šæ—¢è€ƒè™‘åŒ…æ•°é‡ï¼Œä¹Ÿè€ƒè™‘æ•°æ®å¤§å°ï¼Œç¡®ä¿åŠæ—¶å“åº”

##### 3.2.2 åŠ¨æ€ Chunk Size è°ƒæ•´ï¼ˆ1781-1790è¡Œï¼‰

æ ¹æ® RTT åŠ¨æ€è°ƒæ•´ chunk sizeï¼š

```python
if client_rtt > 1000:
    dynamic_chunk_size = 20  # æå¼±ç½‘æ›´æ¿€è¿›çš„æ‰“åŒ…
elif client_rtt > 300:
    dynamic_chunk_size = 8
else:
    dynamic_chunk_size = 1
```

**æ˜ å°„å…³ç³»**ï¼š
- **RTT < 300ms**ï¼šchunk_size = 1ï¼ˆå¼ºç½‘ï¼Œæ— éœ€æ‰“åŒ…ï¼‰
- **RTT > 300ms**ï¼šchunk_size = 8ï¼ˆå¼±ç½‘ï¼Œé€‚åº¦æ‰“åŒ…ï¼‰
- **RTT > 1000ms**ï¼šchunk_size = 20ï¼ˆæå¼±ç½‘ï¼Œæ¿€è¿›æ‰“åŒ…ï¼‰

##### 3.2.3 é™æ€ System Prompt æ³¨å…¥ï¼ˆ1796-1821è¡Œï¼‰

æ³¨å…¥é™æ€æŒ‡ä»¤åˆ° System Promptï¼Œä¿æŒ KV Cache å‘½ä¸­ï¼š

```python
STATIC_SYS_INSTRUCTION = (
    "\n[System Instruction: You are network-aware. "
    "The user will provide their current Network RTT at the end of their message. "
    "If RTT > 300ms, answer concisely and strictly. "
    "If RTT < 100ms, answer comprehensively.]"
)

# å¦‚æœç¬¬ä¸€æ¡æ˜¯ systemï¼Œè¿½åŠ æŒ‡ä»¤
if messages[0].get("role") == "system":
    if "System Instruction: You are network-aware" not in messages[0]["content"]:
        messages[0]["content"] += STATIC_SYS_INSTRUCTION
else:
    # å¦‚æœæ²¡æœ‰ systemï¼Œæ’å…¥ä¸€æ¡æ–°çš„
    messages.insert(0, {
        "role": "system",
        "content": STATIC_SYS_INSTRUCTION.strip()
    })
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **KV Cache å‹å¥½**ï¼šé™æ€æŒ‡ä»¤ä¸ä¼šå˜åŒ–ï¼Œä¿è¯æ¨ç†å¼•æ“çš„ Prefix Cache å‘½ä¸­
- **æ™ºèƒ½æ£€æµ‹**ï¼šé¿å…é‡å¤æ³¨å…¥ï¼Œä¿æŒ System Prompt çš„æ•´æ´

##### 3.2.4 åŠ¨æ€ User Prompt RTT æ³¨å…¥ï¼ˆ1823-1836è¡Œï¼‰

å°†å½“å‰ RTT å€¼æ³¨å…¥åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­ï¼š

```python
if len(messages) > 0 and messages[-1].get("role") == "user":
    user_content = messages[-1]["content"]
    
    net_status = "Poor" if client_rtt > 300 else ("Excellent" if client_rtt < 100 else "Normal")
    
    rtt_injection = f"\n\n<network_context>\n  <rtt>{int(client_rtt)}ms</rtt>\n  <status>{net_status}</status>\n</network_context>"
    
    messages[-1]["content"] = user_content + rtt_injection
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **é›¶ç¼“å­˜æˆæœ¬**ï¼šç”¨æˆ·æ¶ˆæ¯æœ¬èº«å°±æ˜¯æ–°çš„ï¼Œæ³¨å…¥åŠ¨æ€æ•°æ®ä¸ä¼šç ´åç¼“å­˜
- **XML æ ¼å¼**ï¼šä½¿ç”¨ç»“æ„åŒ–æ ‡ç­¾ï¼Œè®©æ¨¡å‹æ›´å®¹æ˜“ç†è§£ç½‘ç»œä¸Šä¸‹æ–‡
- **çŠ¶æ€æè¿°**ï¼šæä¾›ç½‘ç»œçŠ¶æ€ï¼ˆExcellent/Normal/Poorï¼‰ï¼Œå¸®åŠ©æ¨¡å‹åšå‡ºæ›´å¥½çš„å†³ç­–

##### 3.2.5 æµå¼å“åº”æ‹¦æˆªï¼ˆ1866-1883è¡Œï¼‰

åœ¨è¿”å›å“åº”å‰ï¼Œæ‹¦æˆªå¹¶æ›¿æ¢ `StreamingResponse` çš„ `body_iterator`ï¼š

```python
if (
    enable_network_optimization
    and dynamic_chunk_size > 1
    and isinstance(final_response, StreamingResponse)
):
    original_iter = final_response.body_iterator
    final_response.body_iterator = network_chunk_wrapper(
        original_iter, dynamic_chunk_size
    )
```

**å…³é”®æœºåˆ¶**ï¼š
- **æ¡ä»¶æ‹¦æˆª**ï¼šåªåœ¨å¯ç”¨ä¼˜åŒ–ä¸” chunk_size > 1 æ—¶æ‰æ‹¦æˆª
- **é€æ˜æ›¿æ¢**ï¼šç›´æ¥æ›¿æ¢ `body_iterator`ï¼Œä¸å½±å“å…¶ä»–é€»è¾‘
- **å‘åå…¼å®¹**ï¼šå¦‚æœæœªå¯ç”¨ä¼˜åŒ–ï¼Œå“åº”æµç¨‹ä¿æŒä¸å˜

---

### 4. Open WebUI å‰ç«¯å¢å¼ºåŠŸèƒ½

#### 4.1 ç½‘ç»œæ¨¡å¼çŠ¶æ€ç®¡ç†

**æ–‡ä»¶ä½ç½®**ï¼š`my-open-webui/src/lib/stores/network.ts`

åˆ›å»ºå…¨å±€çŠ¶æ€å­˜å‚¨ï¼š

```typescript
import { writable } from 'svelte/store';

// é»˜è®¤å…³é—­ (false)
export const networkMode = writable(false);
```

**ä½œç”¨**ï¼šæä¾›å…¨å±€çš„ç½‘ç»œä¼˜åŒ–å¼€å…³çŠ¶æ€ï¼Œä¾›å¤šä¸ªç»„ä»¶å…±äº«ã€‚

#### 4.2 WiFi æŒ‰é’® UI ç»„ä»¶

**æ–‡ä»¶ä½ç½®**ï¼š`my-open-webui/src/lib/components/chat/MessageInput.svelte`

åœ¨èŠå¤©è¾“å…¥æ¡†å·¥å…·æ ä¸­æ·»åŠ  WiFi æŒ‰é’®ï¼š

```svelte
<script lang="ts">
    import { networkMode } from '$lib/stores/network';
    // ...
</script>

<!-- åœ¨å·¥å…·æ éƒ¨åˆ† -->
<button
    on:click={() => { $networkMode = !$networkMode; }}
    type="button"
    class="group p-[7px] flex gap-1.5 items-center text-sm rounded-full transition-colors duration-300 {$networkMode
        ? ' text-blue-500 dark:text-blue-400 bg-blue-50 hover:bg-blue-100'
        : 'bg-transparent text-gray-400 dark:text-gray-500 hover:bg-gray-50'}"
    title="Network Aware Mode (Weak Signal Optimization)"
>
    <svg class="w-5 h-5">
        <path d="M5 12.55a11 11 0 0 1 14.08 0" />
        <path d="M1.42 9a16 16 0 0 1 21.16 0" />
        <path d="M8.53 16.11a6 6 0 0 1 6.95 0" />
        <line x1="12" y1="20" x2="12.01" y2="20" />
    </svg>
</button>
```

**åŠŸèƒ½ç‰¹ç‚¹**ï¼š
- **å¯è§†åŒ–çŠ¶æ€**ï¼šè“è‰²è¡¨ç¤ºæ¿€æ´»ï¼Œç°è‰²è¡¨ç¤ºå…³é—­
- **ä¸€é”®åˆ‡æ¢**ï¼šç‚¹å‡»å³å¯å¼€å¯/å…³é—­ç½‘ç»œä¼˜åŒ–æ¨¡å¼
- **å®æ—¶åé¦ˆ**ï¼šçŠ¶æ€å˜åŒ–ç«‹å³ç”Ÿæ•ˆ

#### 4.3 å‚æ•°æ³¨å…¥åˆ°è¯·æ±‚

**æ–‡ä»¶ä½ç½®**ï¼š`my-open-webui/src/lib/components/chat/Chat.svelte`

åœ¨å‘é€æ¶ˆæ¯æ—¶ï¼Œå°† `network_aware` å‚æ•°æ³¨å…¥åˆ°è¯·æ±‚ä¸­ï¼š

```svelte
<script lang="ts">
    import { networkMode } from '$lib/stores/network';
    // ...
    
    const submitMessage = async (...) => {
        // ...
        let params = { ...model.params };
        params.network_aware = $networkMode;  // æ³¨å…¥ç½‘ç»œä¼˜åŒ–å¼€å…³
        // ...
    }
</script>
```

**æ•°æ®æµ**ï¼š
1. ç”¨æˆ·ç‚¹å‡» WiFi æŒ‰é’® â†’ `$networkMode` çŠ¶æ€æ›´æ–°
2. å‘é€æ¶ˆæ¯æ—¶ â†’ `params.network_aware = $networkMode`
3. åç«¯æ¥æ”¶ â†’ æ ¹æ® `params.network_aware` å†³å®šæ˜¯å¦å¯ç”¨ä¼˜åŒ–

---

## ğŸ§ª å®éªŒè®¾è®¡

### å®éªŒè„šæœ¬ï¼š`timeline_experiment.py`

#### å®éªŒç›®æ ‡

éªŒè¯ Network-Aware è°ƒåº¦ç›¸æ¯” Baseline è°ƒåº¦çš„ä¼˜åŠ¿ï¼š
- **Baseline æ¨¡å¼**ï¼šæ‰€æœ‰ç”¨æˆ·ä½¿ç”¨ç›¸åŒçš„ä¼˜å…ˆçº§ï¼ˆhealth_factor = 1.0ï¼‰
- **Network-Aware æ¨¡å¼**ï¼šæ ¹æ®ç”¨æˆ·ç½‘ç»œ RTT åŠ¨æ€è°ƒæ•´ä¼˜å…ˆçº§ï¼ˆhealth_factor = exp(-RTT / 500)ï¼‰

#### æ ¸å¿ƒå‡è®¾

1. **GPU ç”Ÿæˆé€Ÿåº¦å›ºå®š**ï¼šæ— è®ºè°ƒåº¦ç­–ç•¥å¦‚ä½•ï¼ŒGPU ç”Ÿæˆ token çš„é€Ÿåº¦æ˜¯æ’å®šçš„ï¼Œç”¨æ»¡ GPU çš„åå
2. **ç½‘ç»œå»¶è¿Ÿå½±å“æœ‰æ•ˆåå**ï¼šchunk åˆ°è¾¾å®¢æˆ·ç«¯çš„æ—¶é—´ = GPU ç”Ÿæˆæ—¶é—´ + ç½‘ç»œå»¶è¿Ÿ
3. **ä¼˜å…ˆè°ƒåº¦ç½‘ç»œå¥½ç”¨æˆ·**ï¼šå¯ä»¥æå‡æ•´ä½“æœ‰æ•ˆååé‡ï¼ˆå®¢æˆ·ç«¯è§†è§’ï¼‰

#### ç”¨æˆ·é…ç½®ç”Ÿæˆ

ä½¿ç”¨æ··åˆé«˜æ–¯åˆ†å¸ƒæ¨¡æ‹ŸçœŸå®çš„ 4 ç±»ç”¨æˆ·ç¾¤ä½“ï¼š

```python
network_clusters = [
    {'prob': 0.50, 'loc': 20,  'scale': 10,  'cat': 'very_good'},  # æå¥½ç½‘ç»œ 50%
    {'prob': 0.40, 'loc': 200, 'scale': 30,  'cat': 'good'},      # æ™®é€šç½‘ç»œ 40%
    {'prob': 0.09, 'loc': 700, 'scale': 80,  'cat': 'bad'},       # è¾ƒå·®ç½‘ç»œ 9%
    {'prob': 0.01, 'loc': 2000,'scale': 400, 'cat': 'very_bad'}   # æå·®ç½‘ç»œ 1%
]
```

#### ç½‘ç»œå»¶è¿Ÿæ¨¡æ‹Ÿ

åœ¨ `send_request()` å‡½æ•°ä¸­æ¨¡æ‹ŸçœŸå®çš„ç½‘ç»œå»¶è¿Ÿï¼š

```python
# å•å‘å»¶è¿Ÿ = (RTT/2) + 0.5 * (RTTÂ²)
rtt_sec = profile.rtt / 1000.0
one_way_delay = (rtt_sec / 2.0) + (0.5 * (rtt_sec ** 2))

# ä¸Šè¡Œå»¶è¿Ÿï¼šè¯·æ±‚å‘é€å‰ sleep
await asyncio.sleep(one_way_delay)

# ä¸‹è¡Œå»¶è¿Ÿï¼šåœ¨ synthetic_arrival_time ä¸­åŠ å…¥
synthetic_arrival_time = observed_arrival_time + one_way_delay
```

#### å®éªŒæµç¨‹

1. **å‡†å¤‡é˜¶æ®µ**ï¼š
   - ç”Ÿæˆç”¨æˆ·é…ç½®ï¼ˆå›ºå®šç§å­ä¿è¯å¯é‡å¤æ€§ï¼‰
   - å›ºå®šè¯·æ±‚åˆ°è¾¾é¡ºåºï¼ˆseed=12345ï¼‰

2. **æ‰§è¡Œé˜¶æ®µ**ï¼š
   - è¿è¡Œ Baseline å®éªŒï¼šæ‰€æœ‰ç”¨æˆ· health_factor = 1.0
   - ç­‰å¾… 2 ç§’
   - è¿è¡Œ Network-Aware å®éªŒï¼šhealth_factor = profile.health

3. **åˆ†æé˜¶æ®µ**ï¼š
   - è®¡ç®—ç´¯è®¡æœ‰æ•ˆ chunk æ›²çº¿ï¼ˆå®¢æˆ·ç«¯è§†è§’ï¼‰
   - å¯¹æ¯”ä¸¤ç§æ¨¡å¼çš„æ€§èƒ½å·®å¼‚
   - ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨

#### å…³é”®æŒ‡æ ‡

- **ç´¯è®¡æœ‰æ•ˆ Chunk æ•°**ï¼šå®¢æˆ·ç«¯å®é™…æ”¶åˆ°çš„ chunk æ•°é‡ï¼ˆè€ƒè™‘ç½‘ç»œå»¶è¿Ÿï¼‰
- **TTFT (Time To First Token)**ï¼šä»è¯·æ±‚å‘é€åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ª chunk çš„æ—¶é—´
- **ECPS (Effective Chunks Per Second)**ï¼šæœ‰æ•ˆååé‡
- **æ€§èƒ½å·®è·**ï¼šNetwork-Aware ç›¸æ¯” Baseline çš„é¢†å…ˆé‡

---

## ğŸ“Š å®éªŒç»“æœ

### å®éªŒé…ç½®

- **ç”¨æˆ·æ•°é‡**ï¼š8192
- **vLLM å¹¶å‘åº¦**ï¼š256ï¼ˆmax_num_seqsï¼‰
- **å®¢æˆ·ç«¯å¹¶å‘åº¦**ï¼š2048
- **ç›®æ ‡ QPS**ï¼š50.0ï¼ˆPoisson åˆ°è¾¾æ¨¡å¼ï¼‰
- **æœ€å¤§ Token æ•°**ï¼š50

### è¾“å‡ºç»“æœ

å®éªŒä¼šç”Ÿæˆä¸¤ä»½æŠ¥å‘Šå’Œä¸¤å¼ å›¾è¡¨ï¼š

1. **å…¨éƒ¨ç”¨æˆ·æŠ¥å‘Š** (`timeline_comparison_all.png`)
   - åŒ…å«æ‰€æœ‰ 4 ç±»ç”¨æˆ·ï¼ˆvery_good, good, bad, very_badï¼‰
   - å±•ç¤ºæ•´ä½“æ€§èƒ½æå‡

2. **æ ¸å¿ƒç”¨æˆ·æŠ¥å‘Š** (`timeline_comparison_core.png`)
   - ä»…åŒ…å«ç½‘ç»œè¾ƒå¥½çš„ç”¨æˆ·ï¼ˆvery_good + goodï¼Œçº¦ 90%ï¼‰
   - å±•ç¤ºå¯¹ä¸»è¦ç”¨æˆ·ç¾¤ä½“çš„ä¼˜åŒ–æ•ˆæœ

### å›¾è¡¨è¯´æ˜

æ¯å¼ å›¾è¡¨åŒ…å« 4 ä¸ªå­å›¾ï¼š

1. **GPU è§†è§’**ï¼šä¸¤ç§æ¨¡å¼åº”å®Œå…¨ç›¸åŒï¼ˆGPU ç”Ÿæˆé€Ÿåº¦å›ºå®šï¼‰
2. **å®¢æˆ·ç«¯è§†è§’**ï¼šNetwork-Aware åº”å§‹ç»ˆé«˜äº Baseline
3. **æ€§èƒ½å·®è·**ï¼šNetwork-Aware çš„é¢†å…ˆé‡ï¼ˆç»¿è‰²ä¸ºæ­£ï¼Œçº¢è‰²ä¸ºè´Ÿï¼‰
4. **æœ‰æ•ˆåå**ï¼šECPS éšæ—¶é—´çš„å˜åŒ–

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### 1. ç¯å¢ƒå‡†å¤‡

#### 1.1 å®‰è£… Node.jsï¼ˆç”¨äºç¼–è¯‘ Open WebUI å‰ç«¯ï¼‰

```bash
# å®‰è£… NVM
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"

# å®‰è£… Node.js 20
nvm install 20
nvm use 20
```

#### 1.2 å…‹éš†å’Œç¼–è¯‘ Open WebUI

```bash
# å…‹éš†ä»“åº“
cd ~
git clone https://github.com/open-webui/open-webui.git my-open-webui
cd my-open-webui

# å®‰è£…ä¾èµ–
npm install --legacy-peer-deps

# ç¼–è¯‘å‰ç«¯
npm run build
```

### 2. ä¿®æ”¹ä»£ç 

#### 2.1 ä¿®æ”¹ Open WebUI å‰ç«¯

**æ–‡ä»¶ 1**ï¼š`my-open-webui/src/routes/+layout.svelte`
- æ·»åŠ  RTT æµ‹é€Ÿé€»è¾‘ï¼ˆ604-638è¡Œï¼‰
- æ·»åŠ  UI æ˜¾ç¤ºç»„ä»¶ï¼ˆ927-937è¡Œï¼‰

**æ–‡ä»¶ 2**ï¼š`my-open-webui/src/lib/stores/network.ts`
- åˆ›å»ºç½‘ç»œæ¨¡å¼çŠ¶æ€å­˜å‚¨

**æ–‡ä»¶ 3**ï¼š`my-open-webui/src/lib/components/chat/MessageInput.svelte`
- æ·»åŠ  WiFi æŒ‰é’®ï¼ˆ1646-1651è¡Œï¼‰

**æ–‡ä»¶ 4**ï¼š`my-open-webui/src/lib/components/chat/Chat.svelte`
- æ³¨å…¥ `network_aware` å‚æ•°åˆ°è¯·æ±‚ï¼ˆ1937è¡Œï¼‰

#### 2.2 ä¿®æ”¹ Open WebUI åç«¯

ç¼–è¾‘ `my-open-webui/backend/open_webui/main.py`ï¼š
- åœ¨ `chat_completion()` å‡½æ•°ä¸­æ·»åŠ  RTT å¤„ç†é€»è¾‘ï¼ˆ1529-1540è¡Œï¼‰
- åœ¨ `process_chat()` å‡½æ•°ä¸­æ·»åŠ ç½‘ç»œä¼˜åŒ–é€»è¾‘ï¼ˆ1710-1884è¡Œï¼‰ï¼š
  - åº”ç”¨å±‚ Nagle ç®—æ³•ï¼ˆ1711-1751è¡Œï¼‰
  - åŠ¨æ€ Chunk Size è°ƒæ•´ï¼ˆ1781-1790è¡Œï¼‰
  - é™æ€ System Prompt æ³¨å…¥ï¼ˆ1796-1821è¡Œï¼‰
  - åŠ¨æ€ User Prompt RTT æ³¨å…¥ï¼ˆ1823-1836è¡Œï¼‰
  - æµå¼å“åº”æ‹¦æˆªï¼ˆ1866-1883è¡Œï¼‰

#### 2.3 ä¿®æ”¹ vLLM å¼•æ“

ä¿®æ”¹ä»¥ä¸‹æ–‡ä»¶ï¼š
- `vllm/vllm/v1/engine/core.py`ï¼šåœ¨ `add_request()` æ–¹æ³•ä¸­æ·»åŠ å¥åº·åº¦æå–é€»è¾‘ï¼ˆ425-474è¡Œï¼‰ï¼Œå–æ¶ˆæ³¨é‡Šé”åˆå§‹åŒ–ï¼ˆ225-226è¡Œï¼‰
- `vllm/vllm/v1/core/sched/scheduler.py`ï¼šæ”¯æŒåŸºäº health_factor çš„ä¼˜å…ˆçº§è°ƒåº¦
- `vllm/vllm/v1/request.py`ï¼šæ·»åŠ  health_factor å­—æ®µæ”¯æŒ

### 3. å¯åŠ¨æœåŠ¡

#### 3.1 å¯åŠ¨ vLLM åç«¯

```bash
CUDA_VISIBLE_DEVICES=1 vllm serve Qwen/Qwen3-4B-Instruct-2507 \
    --max-num-seqs 256 \
    --scheduling-policy priority
```

**æ³¨æ„**ï¼šç¡®ä¿ä½¿ç”¨çš„æ˜¯ä¿®æ”¹åçš„ Network-Aware ç‰ˆæœ¬ vLLMã€‚

#### 3.2 å¯åŠ¨ Open WebUI å‰ç«¯

**å¦‚æœå®¹å™¨å·²å­˜åœ¨ï¼ˆé‡å¯æœåŠ¡å™¨åï¼‰**ï¼š
```bash
docker start open-webui
```

**å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œæˆ–å®¹å™¨è¢«åˆ é™¤**ï¼š
```bash
docker run -d \
  -p 8080:8080 \
  -v open-webui-data:/app/backend/data \
  -v /home/argustest/my-open-webui/backend:/app/backend \
  -v /home/argustest/my-open-webui/build:/app/build \
  -e OPENAI_API_BASE_URL=http://172.17.0.1:8000/v1 \
  -e OPENAI_API_KEY=EMPTY \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```

**è¿›å…¥å®¹å™¨è°ƒè¯•**ï¼ˆå¦‚éœ€è¦ï¼‰ï¼š
```bash
docker exec -it open-webui bash
```

#### 3.3 å¯åŠ¨å†…ç½‘ç©¿é€ï¼ˆå¯é€‰ï¼Œç”¨äºå¤–ç½‘è®¿é—®ï¼‰

ä½¿ç”¨ Cloudflare Tunnel å®ç°å†…ç½‘ç©¿é€ï¼š

##### 3.3.1 å¿«é€Ÿå¯åŠ¨ï¼ˆä¸´æ—¶ç½‘å€ï¼‰

```bash
# å¯åŠ¨ Cloudflare Tunnelï¼ˆä¸´æ—¶ç½‘å€ï¼‰
nohup cloudflared tunnel --url http://127.0.0.1:8080 > tunnel.log 2>&1 &

# æŸ¥çœ‹ç”Ÿæˆçš„å…¬ç½‘é“¾æ¥
grep "trycloudflare.com" tunnel.log
```

**è¯´æ˜**ï¼š
- æ¯æ¬¡å¯åŠ¨å†…ç½‘ç©¿é€ï¼Œå¾—åˆ°çš„ç½‘å€å¯èƒ½ä¸ä¸€æ ·ï¼ˆä¸´æ—¶ç½‘å€ï¼‰
- ç”Ÿæˆçš„é“¾æ¥ï¼ˆä¾‹å¦‚ `https://happy-xx-xx.trycloudflare.com`ï¼‰å¯ä»¥åˆ†äº«ç»™ä»»ä½•äººè®¿é—®

##### 3.3.2 è‡ªå®šä¹‰åŸŸåéƒ¨ç½²ï¼ˆæŒä¹…åŒ–ï¼‰

**æ­¥éª¤ 1ï¼šåˆ›å»ºéš§é“**

```bash
bash cloudflare_tunnel_setup.sh
```

**æ­¥éª¤ 2ï¼šé…ç½®åŸŸå**

1. ç™»å½• Cloudflare Dashboard: https://dash.cloudflare.com
2. é€‰æ‹©åŸŸåï¼ˆä¾‹å¦‚ `riverli1616.uk`ï¼‰
3. è¿›å…¥ 'Zero Trust' > 'Networks' > 'Tunnels'
4. æ‰¾åˆ°éš§é“ `open-webui`ï¼Œç‚¹å‡» 'Configure'
5. åœ¨ 'Public Hostname' ä¸­æ·»åŠ ï¼š
   - Subdomain: `@` (æˆ–ç•™ç©º)
   - Domain: `riverli1616.uk`
   - Service: `http://localhost:8080`

**æ­¥éª¤ 3ï¼šè®¾ç½®ç³»ç»ŸæœåŠ¡ï¼ˆæ¨èï¼‰**

```bash
sudo bash setup_cloudflare_service.sh
```

**æœåŠ¡ç®¡ç†å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sudo systemctl status cloudflared-tunnel

# æŸ¥çœ‹æ—¥å¿—
tail -f ~/cloudflare_tunnel.log

# é‡å¯æœåŠ¡
sudo systemctl restart cloudflared-tunnel

# åœæ­¢æœåŠ¡
sudo systemctl stop cloudflared-tunnel
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ–­å¼€ SSH åç»§ç»­è¿è¡Œ
- âœ… æœåŠ¡å™¨é‡å¯åè‡ªåŠ¨å¯åŠ¨
- âœ… è¿›ç¨‹å´©æºƒåè‡ªåŠ¨é‡å¯
- âœ… ç³»ç»Ÿçº§ç›‘æ§å’Œç®¡ç†

#### 3.4 é‡æ–°ç¼–è¯‘å‰ç«¯ï¼ˆä¿®æ”¹ä»£ç åï¼‰

å¦‚æœä¿®æ”¹äº†å‰ç«¯ä»£ç ï¼Œéœ€è¦é‡æ–°ç¼–è¯‘ï¼š

```bash
cd /home/argustest/my-open-webui
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
nvm use 20
npm run build
```

ç„¶åé‡å¯å®¹å™¨ä½¿ä¿®æ”¹ç”Ÿæ•ˆï¼š

```bash
docker restart open-webui
```

### 4. è¿è¡Œå®éªŒ

```bash

python timeline_experiment.py \
    --vllm-url http://localhost:8000/v1 \
    --num-users 8192 \
    --max-tokens 50 \
    --concurrency 256 \
    --client-concurrency 2048 \
    --qps 50.0
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### 1. ç³»ç»Ÿè¿è¡Œæ•ˆæœ

- **Open WebUI ç•Œé¢**ï¼š
  - å³ä¸‹è§’æ˜¾ç¤ºå®æ—¶ RTT å’Œç½‘ç»œçŠ¶æ€
  - èŠå¤©è¾“å…¥æ¡†æ—æ˜¾ç¤º WiFi æŒ‰é’®ï¼ˆè“è‰²=æ¿€æ´»ï¼Œç°è‰²=å…³é—­ï¼‰
- **vLLM æ—¥å¿—**ï¼šæ˜¾ç¤ºæ¯ä¸ªè¯·æ±‚çš„ health_factor å€¼
- **è°ƒåº¦è¡Œä¸º**ï¼šç½‘ç»œå¥½çš„ç”¨æˆ·è¯·æ±‚ä¼˜å…ˆè¢«è°ƒåº¦
- **ä¼ è¾“ä¼˜åŒ–**ï¼šå¼±ç½‘ç¯å¢ƒä¸‹ï¼ŒTCP åŒ…æ•°é‡æ˜¾è‘—å‡å°‘ï¼ˆé€šè¿‡åº”ç”¨å±‚ Nagle ç®—æ³•ï¼‰
- **Prompt ä¼˜åŒ–**ï¼šæ¨¡å‹æ ¹æ®ç½‘ç»œçŠ¶å†µè‡ªåŠ¨è°ƒæ•´å›å¤é•¿åº¦ï¼ˆé€šè¿‡ Prompt æ³¨å…¥ï¼‰

### 2. å®éªŒç»“æœ

- **ç´¯è®¡æœ‰æ•ˆ Chunk æ›²çº¿**ï¼šNetwork-Aware åº”å§‹ç»ˆé«˜äº Baseline
- **TTFT æ”¹å–„**ï¼šNetwork-Aware çš„å¹³å‡ TTFT åº”ä½äº Baseline
- **æœ‰æ•ˆååæå‡**ï¼šECPS åº”æ˜¾è‘—æå‡

---



## ğŸ“ æŠ€æœ¯äº®ç‚¹

1. **ç«¯åˆ°ç«¯é›†æˆ**ï¼šä»å®¢æˆ·ç«¯ RTT æµ‹é‡åˆ°æœåŠ¡ç«¯è°ƒåº¦å†³ç­–çš„å®Œæ•´é“¾è·¯
2. **å®æ—¶æ„ŸçŸ¥**ï¼šå‰ç«¯æ¯ 2 ç§’è‡ªåŠ¨æ›´æ–°ç½‘ç»œçŠ¶æ€
3. **è‡ªåŠ¨æ³¨å…¥**ï¼šé€šè¿‡ Fetch æ‹¦æˆªå®ç°é›¶ä¾µå…¥çš„å‚æ•°æ³¨å…¥
4. **å¯è§†åŒ–å±•ç¤º**ï¼šå®æ—¶æ˜¾ç¤ºç½‘ç»œçŠ¶æ€ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
5. **ç§‘å­¦éªŒè¯**ï¼šé€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯ç³»ç»Ÿä¼˜åŠ¿
6. **åº”ç”¨å±‚ä¼˜åŒ–**ï¼šå®ç°åº”ç”¨å±‚ Nagle ç®—æ³•ï¼Œå‡å°‘ TCP åŒ…æ•°é‡
7. **æ™ºèƒ½ Prompt å·¥ç¨‹**ï¼šé™æ€ System Prompt + åŠ¨æ€ User Promptï¼Œå…¼é¡¾ KV Cache å’Œç½‘ç»œæ„ŸçŸ¥
8. **ç”¨æˆ·å¯æ§**ï¼šæä¾› WiFi æŒ‰é’®ï¼Œç”¨æˆ·å¯æ‰‹åŠ¨å¼€å¯/å…³é—­ç½‘ç»œä¼˜åŒ–
9. **å¤šç»´åº¦ä¼˜åŒ–**ï¼šåŒæ—¶ä¼˜åŒ–è°ƒåº¦å±‚ï¼ˆvLLMï¼‰å’Œä¼ è¾“å±‚ï¼ˆTCP chunkingï¼‰
10. **ç”Ÿäº§çº§éƒ¨ç½²**ï¼šæ”¯æŒ Cloudflare Tunnel å’Œ systemd æœåŠ¡ï¼Œç¡®ä¿æœåŠ¡ç¨³å®šæ€§

---

## ğŸ¯ æœªæ¥æ”¹è¿›æ–¹å‘

1. **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®å®æ—¶ç½‘ç»œçŠ¶æ€åŠ¨æ€è°ƒæ•´å¥åº·åº¦è®¡ç®—å‚æ•°
2. **å¤šç»´åº¦æ„ŸçŸ¥**ï¼šä¸ä»…è€ƒè™‘ RTTï¼Œè¿˜è€ƒè™‘ä¸¢åŒ…ç‡ã€å¸¦å®½ç­‰å› ç´ 
3. **è‡ªé€‚åº”è°ƒåº¦**ï¼šæ ¹æ®ç³»ç»Ÿè´Ÿè½½è‡ªåŠ¨è°ƒæ•´è°ƒåº¦ç­–ç•¥
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šå‡å°‘ RTT æµ‹é‡å¼€é”€ï¼Œä¼˜åŒ–è°ƒåº¦ç®—æ³•æ•ˆç‡
5. **æ™ºèƒ½ Chunk Size**ï¼šæ ¹æ®å†å²ç½‘ç»œçŠ¶å†µå’Œå½“å‰è´Ÿè½½åŠ¨æ€è°ƒæ•´ chunk size
6. **A/B æµ‹è¯•æ¡†æ¶**ï¼šæ”¯æŒå¯¹æ¯”ä¸åŒä¼˜åŒ–ç­–ç•¥çš„æ•ˆæœ
7. **ç›‘æ§å’Œå‘Šè­¦**ï¼šé›†æˆ Prometheus/Grafanaï¼Œå®æ—¶ç›‘æ§ç½‘ç»œä¼˜åŒ–æ•ˆæœ
8. **å¤šæ¨¡å‹æ”¯æŒ**ï¼šé’ˆå¯¹ä¸åŒæ¨¡å‹ï¼ˆGPTã€Claudeã€Llama ç­‰ï¼‰ä¼˜åŒ– Prompt æ³¨å…¥ç­–ç•¥

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- vLLM: [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)
- Open WebUI: [https://github.com/open-webui/open-webui](https://github.com/open-webui/open-webui)
- SvelteKit: [https://kit.svelte.dev/](https://kit.svelte.dev/)

---

## ğŸ‘¥ ä½œè€…

æœ¬é¡¹ç›®ä¸ºè®¡ç®—æœºç½‘ç»œè¯¾ç¨‹å®éªŒé¡¹ç›®ï¼Œå®ç°äº†ç½‘ç»œæ„ŸçŸ¥çš„ LLM Token è°ƒåº¦ç³»ç»Ÿï¼Œå¹¶å®æœºéƒ¨ç½²ã€‚

---

## ğŸ“„ License

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

