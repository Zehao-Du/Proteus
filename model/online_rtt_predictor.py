#!/usr/bin/env python3
import time
import collections
import numpy as np
import torch
import torch.nn as nn
from bcc import BPF
from collections import deque
import random
import os
import copy
from sklearn.preprocessing import StandardScaler

# ================= é…ç½®ä¸è¶…å‚æ•° =================
INTERFACE = "eth0"  # ç›‘å¬çš„ç½‘å¡ï¼Œè™½ç„¶ kprobe æ˜¯å†…æ ¸çº§çš„ï¼Œä½†é€»è¾‘ä¸Šæˆ‘ä»¬å…³æ³¨è¯¥ç½‘å¡æµé‡
POLL_INTERVAL = 0.05  # 50ms é‡‡æ ·ä¸€æ¬¡
WINDOW_SIZE = 10      # æ»šåŠ¨çª—å£ç»Ÿè®¡ç‰¹å¾
SEQ_LEN = 10          # LSTM è¾“å…¥åºåˆ—é•¿åº¦
PRED_LEN = 10         # LSTM é¢„æµ‹æ­¥é•¿
HIDDEN_SIZE = 256
NUM_LAYERS = 2

# åœ¨çº¿å­¦ä¹ å‚æ•°
WARMUP_STEPS = 500    # å‰ 500 ä¸ªç‚¹(çº¦25ç§’)åªæ”¶é›†æ•°æ®ï¼Œç”¨äºæ‹Ÿåˆ Scaler å’Œåˆå§‹åŒ–
UPDATE_INTERVAL = 10  # æ¯ 10 ä¸ªæ•°æ®ç‚¹è®­ç»ƒä¸€æ¬¡
BATCH_SIZE = 32
MEMORY_SIZE = 1000
ONLINE_LR = 0.001     # åœ¨çº¿å¾®è°ƒå­¦ä¹ ç‡

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ================= eBPF å†…æ ¸ä»£ç  (ä¿æŒä¸å˜) =================
BPF_PROGRAM = r"""
#include <uapi/linux/ptrace.h>
#include <linux/types.h>
#include <net/sock.h>
#include <bcc/proto.h>
#include <linux/tcp.h>
#include <linux/skbuff.h>

BPF_PERF_OUTPUT(rtt_events);
BPF_PERF_OUTPUT(retrans_events);

struct rtt_data_t {
    u32 rtt;
    u32 cwnd;
    u32 len;
};

struct retrans_data_t { u32 dummy; };

int trace_tcp_rcv(struct pt_regs *ctx, struct sock *sk, struct sk_buff *skb)
{
    struct tcp_sock *ts = (struct tcp_sock *)sk;
    u32 srtt = ts->srtt_us >> 3;
    if (srtt == 0) return 0;

    struct rtt_data_t data = {};
    data.rtt = srtt;
    data.cwnd = ts->snd_cwnd;
    if (skb) data.len = skb->len;
    else data.len = 0;

    rtt_events.perf_submit(ctx, &data, sizeof(data));
    return 0;
}

int trace_retransmit(struct pt_regs *ctx, struct sock *sk)
{
    struct retrans_data_t data = {};
    retrans_events.perf_submit(ctx, &data, sizeof(data));
    return 0;
}
"""

# ================= LSTM æ¨¡å‹å®šä¹‰ =================
class MultiStepLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_len):
        super(MultiStepLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Linear(128, output_len) 
        )

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

class AsymmetricMSELoss(nn.Module):
    def __init__(self, penalty=10.0): 
        super().__init__()
        self.penalty = penalty

    def forward(self, pred, target):
        error = target - pred
        # æƒ©ç½šä½ä¼° (é¢„æµ‹ < çœŸå®)
        loss = torch.where(error > 0, error**2 * self.penalty, error**2)
        return torch.mean(loss)

# ================= åœ¨çº¿å­¦ä¹  Agent =================
class OnlineLSTMAgent:
    def __init__(self, input_size):
        self.device = DEVICE
        self.model = MultiStepLSTM(input_size, HIDDEN_SIZE, NUM_LAYERS, PRED_LEN).to(self.device)
        self.criterion = AsymmetricMSELoss(penalty=10.0)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=ONLINE_LR)
        self.memory = deque(maxlen=MEMORY_SIZE)
        
        # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡
        if os.path.exists("best_lstm_grid_search.pth"):
            try:
                # æ³¨æ„ï¼šå¦‚æœç‰¹å¾æ•°é‡ä¸ä¸€è‡´ï¼ŒåŠ è½½ä¼šå¤±è´¥ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€å•çš„ä¿æŠ¤
                state = torch.load("best_lstm_grid_search.pth", map_location=self.device)
                # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…ï¼ˆç²—ç•¥æ£€æŸ¥ï¼‰
                if state['lstm.weight_ih_l0'].shape[1] == input_size:
                    self.model.load_state_dict(state)
                    print("âœ… Loaded pre-trained model weights.")
                else:
                    print("âš ï¸ Dimension mismatch in pre-trained model. Starting fresh.")
            except Exception as e:
                print(f"âš ï¸ Load failed: {e}. Starting fresh.")
        else:
            print("â„¹ï¸ No pre-trained model found. Will learn from scratch.")

    def predict(self, seq_array):
        """
        seq_array: shape (1, seq_len, features)
        """
        self.model.eval()
        with torch.no_grad():
            x = torch.FloatTensor(seq_array).to(self.device)
            # ç¡®ä¿æœ‰ batch ç»´åº¦
            if x.ndim == 2: x = x.unsqueeze(0)
            pred = self.model(x)
        self.model.train()
        return pred.cpu().numpy()

    def train_step(self, x_seq, y_true):
        """
        x_seq: (seq_len, features)
        y_true: (pred_len, ) -> å®é™…ä¸Šæˆ‘ä»¬ä¸»è¦å…³å¿ƒ y_true[-1]
        """
        self.memory.append((x_seq, y_true))
        
        if len(self.memory) < BATCH_SIZE:
            return 0.0
        
        # Experience Replay
        batch = random.sample(self.memory, BATCH_SIZE)
        bx, by = zip(*batch)
        bx = torch.FloatTensor(np.array(bx)).to(self.device)
        by = torch.FloatTensor(np.array(by)).to(self.device)
        
        self.optimizer.zero_grad()
        preds = self.model(bx)
        loss = self.criterion(preds, by)
        loss.backward()
        self.optimizer.step()
        
        return loss.item()

# ================= æ™ºèƒ½é‡‡é›†ä¸å¤„ç†æ ¸å¿ƒ =================
class SmartMonitor:
    def __init__(self):
        print("âš¡ Initializing eBPF...")
        self.bpf = BPF(text=BPF_PROGRAM)
        self.bpf.attach_kprobe(event="tcp_rcv_established", fn_name="trace_tcp_rcv")
        self.bpf.attach_kprobe(event="tcp_retransmit_skb", fn_name="trace_retransmit")
        
        # eBPF Buffer å›è°ƒ
        self.bpf["rtt_events"].open_perf_buffer(self._handle_rtt)
        self.bpf["retrans_events"].open_perf_buffer(self._handle_retrans)
        
        # åŸå§‹æ•°æ®æš‚å­˜
        self.raw_rtt = []
        self.raw_cwnd = []
        self.total_bytes = 0
        self.retrans_count = 0
        
        # ç‰¹å¾å·¥ç¨‹éœ€è¦çš„å†å²çŠ¶æ€
        self.rolling_window = deque(maxlen=WINDOW_SIZE)
        self.prev_log_rtt = 0.0
        
        # åœ¨çº¿å­¦ä¹ éœ€è¦çš„åºåˆ— Buffer
        # å­˜å‚¨å¤„ç†å½’ä¸€åŒ–åçš„ç‰¹å¾å‘é‡
        self.input_seq_buffer = deque(maxlen=SEQ_LEN)
        
        # æ ‡ç­¾ç”Ÿæˆ Buffer (å­˜å‚¨ä¹‹å‰çš„ featuresï¼Œç­‰å¾…æœªæ¥çš„ RTT æ¥æ ‡è®°å®ƒ)
        # æ ¼å¼: (timestamp, feature_seq, raw_rtt_target)
        self.pending_training_data = deque(maxlen=PRED_LEN + 5)
        
        self.agent = None # ç¨ååˆå§‹åŒ–
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()
        
        # çŠ¶æ€æœº
        self.warmup_data_X = []
        self.warmup_data_y = []
        self.steps = 0
        self.is_ready = False

    def _handle_rtt(self, cpu, data, size):
        event = self.bpf["rtt_events"].event(data)
        self.raw_rtt.append(event.rtt)
        self.raw_cwnd.append(event.cwnd)
        self.total_bytes += event.len

    def _handle_retrans(self, cpu, data, size):
        self.retrans_count += 1

    def _process_interval(self):
        """æ¯ 50ms è°ƒç”¨ä¸€æ¬¡ï¼Œèšåˆæ•°æ®å¹¶è¿›è¡Œå¤„ç†"""
        # 1. åŸºç¡€èšåˆ
        if not self.raw_rtt:
            avg_rtt = self.rolling_window[-1]['avg_rtt_us'] if self.rolling_window else 0
            p95_rtt = avg_rtt
            avg_cwnd = 0
        else:
            avg_rtt = np.mean(self.raw_rtt)
            p95_rtt = np.percentile(self.raw_rtt, 95)
            avg_cwnd = np.mean(self.raw_cwnd)
        
        throughput = self.total_bytes / POLL_INTERVAL
        r_count = self.retrans_count
        
        # 2. æ„é€ åŸºç¡€ Metrics å­—å…¸
        metrics = {
            'avg_rtt_us': avg_rtt,
            'p95_rtt_us': p95_rtt,
            'avg_cwnd': avg_cwnd,
            'throughput_bps': throughput,
            'retrans_count': r_count
        }
        self.rolling_window.append(metrics)
        
        # 3. è®¡ç®—é«˜çº§ç‰¹å¾ (Feature Engineering)
        # å¿…é¡»ä¸è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºå®Œå…¨ä¸€è‡´:
        # ['log_rtt', 'p95_rtt_us', 'avg_cwnd', 'throughput_bps', 'retrans_count', 'rolling_avg_rtt', 'rtt_diff']
        
        # å¤„ç† Log RTT
        safe_rtt = max(avg_rtt, 1.0) # é˜²æ­¢ log(0)
        log_rtt = np.log1p(safe_rtt)
        
        # å¤„ç† Rolling Avg
        if len(self.rolling_window) > 0:
            roll_avg = np.mean([m['avg_rtt_us'] for m in self.rolling_window])
        else:
            roll_avg = avg_rtt
            
        # å¤„ç† Diff
        rtt_diff = log_rtt - self.prev_log_rtt
        self.prev_log_rtt = log_rtt
        
        # ç»„åˆç‰¹å¾å‘é‡ (æœªå½’ä¸€åŒ–)
        feature_vector = np.array([
            log_rtt,
            p95_rtt,
            avg_cwnd,
            throughput,
            r_count,
            roll_avg,
            rtt_diff
        ])
        
        # 4. çŠ¶æ€æœºé€»è¾‘
        self.steps += 1
        
        # === é˜¶æ®µ A: çƒ­èº« (Warmup) ===
        if not self.is_ready:
            print(f"ğŸ”¥ Warming up: {self.steps}/{WARMUP_STEPS}", end='\r')
            self.warmup_data_X.append(feature_vector)
            self.warmup_data_y.append(log_rtt) # ç›®æ ‡æ˜¯ log_rtt
            
            if self.steps >= WARMUP_STEPS:
                self._finish_warmup()
            return

        # === é˜¶æ®µ B: åœ¨çº¿è¿è¡Œ (Online) ===
        
        # B1. å½’ä¸€åŒ–å½“å‰ç‰¹å¾
        # æ³¨æ„: reshape(1, -1) å› ä¸º scaler æœŸæœ› 2D æ•°ç»„
        feat_scaled = self.scaler_X.transform(feature_vector.reshape(1, -1))[0]
        
        # B2. åŠ å…¥è¾“å…¥åºåˆ— Buffer
        self.input_seq_buffer.append(feat_scaled)
        
        # åªæœ‰å½“åºåˆ—å¡«æ»¡ (10ä¸ª) æ‰èƒ½è¿›è¡Œé¢„æµ‹å’Œè®­ç»ƒ
        if len(self.input_seq_buffer) == SEQ_LEN:
            seq_data = np.array(self.input_seq_buffer) # Shape: (10, 7)
            
            # --- é¢„æµ‹ (Prediction) ---
            # é¢„æµ‹æœªæ¥ç¬¬10æ­¥çš„ Log RTT
            pred_scaled = self.agent.predict(seq_data) # Shape: (1, 10)
            
            # å–æœ€åä¸€æ­¥é¢„æµ‹å€¼ï¼Œåå½’ä¸€åŒ–ï¼Œè½¬å› RTT
            pred_log_rtt = self.scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0, -1]
            pred_rtt_us = np.expm1(pred_log_rtt)
            
            # æ‰“å°ç›‘æ§
            diff = pred_rtt_us - avg_rtt
            marker = "ğŸ”´" if diff > 5000 else ("ğŸŸ¢" if abs(diff) < 1000 else "âšª")
            print(f"Step {self.steps} | Real: {avg_rtt:.0f}us | Pred: {pred_rtt_us:.0f}us | Diff: {diff:+.0f} {marker}")
            
            # --- è®­ç»ƒæ•°æ®å‡†å¤‡ (Label Generation) ---
            # ç°åœ¨çš„ seq_data å¯¹åº”æ—¶åˆ» T-9 åˆ° Tã€‚
            # æˆ‘ä»¬æƒ³é¢„æµ‹ T+1 åˆ° T+10ã€‚
            # ä½†å®é™…ä¸Šï¼Œæˆ‘ä»¬åªæœ‰ç­‰åˆ° T+10 å‘ç”Ÿæ—¶ï¼Œæ‰èƒ½çŸ¥é“é‚£æ—¶çš„çœŸå®å€¼ã€‚
            # æ‰€ä»¥æˆ‘ä»¬å°† (Current Sequence, Current Time) å­˜å…¥ pending é˜Ÿåˆ—ã€‚
            # å½“æ—¶é—´æµé€ï¼Œæœªæ¥çš„çœŸå®å€¼å‡ºç°æ—¶ï¼Œæˆ‘ä»¬å†å›è¿‡å¤´æ¥è®­ç»ƒã€‚
            
            # è¿™é‡Œç®€åŒ–é€»è¾‘ï¼šæˆ‘ä»¬è®­ç»ƒæ¨¡å‹é¢„æµ‹ T+1 (Next Step)
            # å®é™…ä¸Š MultiStepLSTM é¢„æµ‹çš„æ˜¯ T+1...T+10
            # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬æš‚å­˜å½“å‰çš„ input sequence
            
            self.pending_training_data.append({
                'seq': copy.deepcopy(seq_data),
                'wait_steps': PRED_LEN, # ç­‰å¾…10æ­¥åæ‰æœ‰å®Œæ•´æ ‡ç­¾
                'future_labels': []
            })
            
            # æ£€æŸ¥ Pending é˜Ÿåˆ—ï¼Œå¡«å……æ ‡ç­¾
            for item in self.pending_training_data:
                if item['wait_steps'] > 0:
                    # è®°å½•å½“å‰çš„çœŸå® Log RTT ä½œä¸ºæœªæ¥çš„æ ‡ç­¾
                    # æ³¨æ„ï¼šè¿™é‡Œè®°å½•çš„æ˜¯ log_rtt (æœªå½’ä¸€åŒ–ï¼Œç¨åç»Ÿä¸€å½’ä¸€åŒ–)
                    item['future_labels'].append(log_rtt)
                    item['wait_steps'] -= 1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å·²ç»æ”¶é›†æ»¡æ ‡ç­¾
            if self.pending_training_data and self.pending_training_data[0]['wait_steps'] == 0:
                ready_item = self.pending_training_data.popleft()
                
                # æ„é€  Label
                y_raw = np.array(ready_item['future_labels'])
                y_scaled = self.scaler_y.transform(y_raw.reshape(-1, 1)).flatten()
                
                # --- è®­ç»ƒ (Training) ---
                if self.steps % UPDATE_INTERVAL == 0:
                    loss = self.agent.train_step(ready_item['seq'], y_scaled)
                    if loss > 0:
                        print(f"   ğŸ› ï¸  Model Updated. Loss: {loss:.4f}")

        # æ¸…ç†æœ¬è½®è®¡æ•°å™¨
        self.raw_rtt = []
        self.raw_cwnd = []
        self.total_bytes = 0
        self.retrans_count = 0

    def _finish_warmup(self):
        print("\nâœ… Warmup complete. Fitting Scalers and initializing Model...")
        
        # 1. æ‹Ÿåˆ Scaler
        X_arr = np.array(self.warmup_data_X)
        y_arr = np.array(self.warmup_data_y).reshape(-1, 1)
        
        self.scaler_X.fit(X_arr)
        self.scaler_y.fit(y_arr)
        
        num_features = X_arr.shape[1]
        print(f"   Features identified: {num_features}")
        
        # 2. åˆå§‹åŒ– Agent
        self.agent = OnlineLSTMAgent(num_features)
        
        # 3. å¡«å…… Buffer ä»¥ä¾¿å¹³æ»‘è¿‡æ¸¡
        # å°†çƒ­èº«æ•°æ®çš„æœ€å10ä¸ªå¡«å……è¿› bufferï¼Œé¿å…å†·å¯åŠ¨ç­‰å¾…
        for vec in self.warmup_data_X[-SEQ_LEN:]:
            scaled = self.scaler_X.transform(vec.reshape(1, -1))[0]
            self.input_seq_buffer.append(scaled)
            
        self.is_ready = True
        print("ğŸš€ Online Prediction & Training Started!")

    def run(self):
        try:
            while True:
                start_t = time.time()
                # 1. è½®è¯¢ eBPF
                self.bpf.perf_buffer_poll(timeout=10) # ms
                
                # 2. æ£€æŸ¥æ—¶é—´é—´éš”æ˜¯å¦æ»¡è¶³å¤„ç†è¦æ±‚
                # ç®€å•çš„ sleep æ§åˆ¶ï¼Œç”Ÿäº§ç¯å¢ƒå¯ä»¥ç”¨ timer
                time.sleep(POLL_INTERVAL) 
                
                # 3. å¤„ç†é€»è¾‘
                self._process_interval()
                
        except KeyboardInterrupt:
            print("\nğŸ›‘ Stopping...")
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            if self.agent:
                torch.save(self.agent.model.state_dict(), "final_online_model.pth")
                print("ğŸ’¾ Model saved to final_online_model.pth")

if __name__ == "__main__":
    monitor = SmartMonitor()
    monitor.run()