import torch
import torch.nn as nn
import numpy as np
from collections import deque
import random
import os
import matplotlib.pyplot as plt

# ================= 1. æ ¸å¿ƒç±»ï¼šSmartTokenPacer (å¸¦å®Œæ•´åœ¨çº¿å­¦ä¹ ) =================

class MultiStepLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_len):
        super(MultiStepLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Linear(128, output_len)
        )

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

class AsymmetricMSELoss(nn.Module):
    def __init__(self, penalty=15.0): 
        super().__init__()
        self.penalty = penalty

    def forward(self, pred, target):
        error = target - pred
        # ä¸¥é‡æƒ©ç½šä½ä¼°ï¼ˆé¢„æµ‹å€¼ < çœŸå®å€¼ï¼‰ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´ç®—åŠ›è¿‡åº¦åˆ†é…å¼•å‘æ‹¥å¡
        loss = torch.where(error > 0, error**2 * self.penalty, error**2)
        return torch.mean(loss)

class SmartTokenPacer:
    def __init__(self, 
                 model_path=None, 
                 input_features=7, 
                 pred_len=10, 
                 learning_rate=0.001):
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.pred_len = pred_len
        self.seq_len = 10
        
        # æ¨¡å‹åˆå§‹åŒ–
        self.model = MultiStepLSTM(input_features, 256, 2, pred_len).to(self.device)
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        
        # åœ¨çº¿å­¦ä¹ ç»„ä»¶ï¼šåˆ‡æ¢ä¸ºéå¯¹ç§°æŸå¤±
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)
        self.loss_fn = AsymmetricMSELoss(penalty=20.0) 
        
        # ç»éªŒæ±  & å»¶è¿Ÿé˜Ÿåˆ—
        self.memory = deque(maxlen=2000)
        self.pending_queue = deque() # å­˜å‚¨ (seq, timestamp) ç­‰å¾…æœªæ¥éªŒè¯
        self.batch_size = 32
        
        # çŠ¶æ€è¿½è¸ª
        self.input_buffer = deque(maxlen=self.seq_len)
        self.min_rtt_window = deque(maxlen=200)
        
        # å¹³æ»‘çŠ¶æ€
        self.smoothed_score = 1.0
        self.smoothed_pred_rtt = None
        
        # å½’ä¸€åŒ–å‚æ•° (Demoä¸­åŠ¨æ€æ›´æ–°ï¼Œå®é™…éƒ¨ç½²åº”å›ºå®š)
        self.scaler_mean = np.zeros(input_features)
        self.scaler_scale = np.ones(input_features)

    def set_scaler(self, mean, scale):
        self.scaler_mean = np.array(mean)
        self.scaler_scale = np.array(scale)
        
    def _update_baseline(self, rtt):
        # ğŸ”§ ä¿®å¤ç‚¹ï¼šå¿½ç•¥å°äº 5ms (5000us) çš„éæ³•å€¼ï¼Œé˜²æ­¢åŸºå‡†çº¿è¢« 0 æ±¡æŸ“
        if rtt > 5000:
            self.min_rtt_window.append(rtt)
        
    def get_baseline(self):
        # ğŸ”§ ä¿®å¤ç‚¹ï¼šå¼ºåˆ¶è®¾ç½®æœ€ä½ç‰©ç†åŸºå‡†ä¸º 30msï¼Œé€‚åº”å…¬ç½‘ç¯å¢ƒ
        if not self.min_rtt_window:
            return 30000.0
        return max(30000.0, min(self.min_rtt_window))

    def step(self, current_metrics):
        """
        Args:
            current_metrics: [log_rtt, rtt_diff, ...]
        Returns:
            health_score (0-1), pred_rtt (float)
        """
        # 1. å‡†å¤‡æ•°æ®
        raw_feats = np.array(current_metrics)
        norm_feats = (raw_feats - self.scaler_mean) / self.scaler_scale
        
        # è§£æçœŸå® RTT (ç”¨äº Label å’Œ Baseline)
        current_real_rtt = np.expm1(raw_feats[0])
        self._update_baseline(current_real_rtt)
        
        self.input_buffer.append(norm_feats)
        
        # === ä¿®å¤ç‚¹åœ¨è¿™é‡Œ ===
        # å¦‚æœæ•°æ®ä¸è¶³ 10 æ­¥ï¼Œä¸ºäº†ä¿è¯è¿”å›å€¼æ ¼å¼ä¸€è‡´ï¼Œå¿…é¡»è¿”å›ä¸¤ä¸ªå€¼
        if len(self.input_buffer) < self.seq_len:
            # è¿”å› (é»˜è®¤æ»¡åˆ†, é»˜è®¤é¢„æµ‹å€¼ä¸º0)
            return 1.0, 0.0  
            
        current_seq = np.array(self.input_buffer)

        # ==========================================
        # 1. åœ¨çº¿å­¦ä¹ é€»è¾‘ (Online Learning)
        # ==========================================
        
        # A. å­˜å…¥å¾…éªŒè¯é˜Ÿåˆ—
        self.pending_queue.append(current_seq.copy())
        
        # B. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®"æˆç†Ÿ"å¯ç”¨äºè®­ç»ƒ
        if len(self.pending_queue) > self.pred_len:
            old_seq = self.pending_queue.popleft()
            target_val = norm_feats[0] 
            self.memory.append((old_seq, target_val))
            
            if len(self.memory) > self.batch_size:
                self._train()

        # ==========================================
        # 2. æ¨ç†é¢„æµ‹ (Inference)
        # ==========================================
        self.model.eval()
        with torch.no_grad():
            x_tensor = torch.FloatTensor(current_seq).unsqueeze(0).to(self.device)
            pred_out = self.model(x_tensor).cpu().numpy()[0, -1]
            
            pred_log_rtt = pred_out * self.scaler_scale[0] + self.scaler_mean[0]
            pred_rtt = np.expm1(pred_log_rtt)

        self.model.train()

        # ==========================================
        # 3. è®¡ç®—å¥åº·åˆ† (Scoring) - æ¿€è¿›ç‰ˆ
        # ==========================================
        
        # A. é¢„æµ‹å€¼å¹³æ»‘ (é™ä½æƒ¯æ€§ï¼ŒåŠ å¿«å“åº”)
        if self.smoothed_pred_rtt is None:
            self.smoothed_pred_rtt = pred_rtt
        else:
            self.smoothed_pred_rtt = 0.5 * pred_rtt + 0.5 * self.smoothed_pred_rtt
            
        # B. åŠ¨æ€é˜ˆå€¼ (æé™æ”¾å®½ç‰ˆ)
        base = self.get_baseline()
        # é’ˆå¯¹å½“å‰ 200ms çš„ç¯å¢ƒï¼Œæˆ‘ä»¬å°†å®‰å…¨åŒºç›´æ¥æ‹‰åˆ° 400ms
        threshold = max(base * 3.0, 200000.0) 
        
        diff = self.smoothed_pred_rtt - threshold
        
        # ğŸ”§ é’ˆå¯¹ 200ms çº§åˆ«ç¯å¢ƒï¼Œé™ä½æ•æ„Ÿåº¦ï¼Œåªæœ‰çœŸæ­£â€œèµ·é£â€æ‰åˆ¹è½¦
        val_for_sigmoid = diff / 1000.0 if abs(diff) > 1000 else diff
        
        sensitivity = 0.02  # æä½æ•æ„Ÿåº¦
        exponent = np.clip(sensitivity * val_for_sigmoid, -15, 15)
        raw_score = 1.0 / (1.0 + np.exp(exponent))
        
        # ğŸ”§ æé€Ÿå“åº”æ¢å¤
        # å¦‚æœé¢„æµ‹å€¼æ­£åœ¨ä¸‹é™ï¼Œè®©åˆ†æ•°å›å‡å¾—å¿«ä¸€ç‚¹
        if hasattr(self, 'prev_pred') and self.smoothed_pred_rtt < self.prev_pred:
            smooth_factor = 0.2
        else:
            smooth_factor = 0.5
        self.prev_pred = self.smoothed_pred_rtt
        
        self.smoothed_score = (1 - smooth_factor) * raw_score + smooth_factor * self.smoothed_score
        
        return self.smoothed_score, self.smoothed_pred_rtt

    def _train(self):
        batch = random.sample(self.memory, self.batch_size)
        bx, by = zip(*batch)
        bx = torch.FloatTensor(np.array(bx)).to(self.device)
        by = torch.FloatTensor(np.array(by)).unsqueeze(1).to(self.device) # (B, 1)
        
        self.optimizer.zero_grad()
        # æ¨¡å‹è¾“å‡º (B, 10)ï¼Œå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥ (B, 1) ä¸ Label å¯¹æ¯”
        preds = self.model(bx)[:, -1].unsqueeze(1)
        loss = self.loss_fn(preds, by)
        loss.backward()
        self.optimizer.step()


# ================= 2. çœŸå®ç½‘ç»œç¯å¢ƒæ¨¡æ‹Ÿå™¨ (æ¨¡ä»¿ Chaos Maker) =================

class NetworkSimulator:
    """
    æ¨¡æ‹ŸçœŸå®çš„ Chaos Maker è¡Œä¸ºï¼š
    ä¸æ˜¯éšæœºè·³å˜ï¼Œè€Œæ˜¯åŸºäºçŠ¶æ€æœº (State Machine) çš„æŒç»­æ€§å¹²æ‰°ã€‚
    """
    def __init__(self, steps):
        self.total_steps = steps
        self.current_step = 0
        
        # çŠ¶æ€å®šä¹‰
        self.STATE_NORMAL = 0
        self.STATE_CONGESTION = 1  # å¸¦å®½æ‰“æ»¡/Bufferbloat
        self.STATE_JITTER = 2      # WiFi æŠ–åŠ¨
        
        self.current_state = self.STATE_NORMAL
        self.state_timer = 0
        
        # ç‰©ç†å‚æ•°
        self.base_rtt = 30 # ms
        self.queue_delay = 0 # æ¨¡æ‹Ÿæ’é˜Ÿç§¯å‹
        
    def step(self):
        self.current_step += 1
        
        # --- 1. çŠ¶æ€åˆ‡æ¢é€»è¾‘ (æ¨¡æ‹Ÿ Chaos Maker å®šæ—¶åˆ‡æ¢åœºæ™¯) ---
        if self.state_timer <= 0:
            # éšæœºé€‰æ‹©æ–°çŠ¶æ€ï¼ŒæŒç»­ 50-150 æ­¥ (2.5s - 7.5s)
            rand = random.random()
            if rand < 0.5:
                self.current_state = self.STATE_NORMAL
                self.state_timer = random.randint(100, 200)
            elif rand < 0.8:
                self.current_state = self.STATE_CONGESTION
                self.state_timer = random.randint(100, 300) # æ‹¥å¡é€šå¸¸æŒç»­è¾ƒä¹…
            else:
                self.current_state = self.STATE_JITTER
                self.state_timer = random.randint(50, 100)
        
        self.state_timer -= 1
        
        # --- 2. æ ¹æ®çŠ¶æ€ç”Ÿæˆ RTT (ç‰©ç†æ¨¡æ‹Ÿ) ---
        noise = np.random.normal(0, 2)
        
        if self.current_state == self.STATE_NORMAL:
            # æ­£å¸¸ç½‘ç»œï¼šä½å»¶è¿Ÿï¼Œå°æ³¢åŠ¨
            # æ¨¡æ‹Ÿé˜Ÿåˆ—æ’ç©º
            self.queue_delay = max(0, self.queue_delay - 5) 
            rtt = self.base_rtt + noise + self.queue_delay
            
        elif self.current_state == self.STATE_CONGESTION:
            # æ‹¥å¡æ¨¡å¼ï¼šBufferbloat ç°è±¡
            # é˜Ÿåˆ—ä¸ä¼šç¬é—´å˜æ»¡ï¼Œè€Œæ˜¯é€æ¸ç´¯ç§¯ (Ramp Up) -> è¿™æ‰æ˜¯ LSTM èƒ½é¢„æµ‹çš„å…³é”®ï¼
            # æ¯æ¬¡ +2ms ~ +5ms
            self.queue_delay = min(400, self.queue_delay + random.uniform(2, 5))
            rtt = self.base_rtt + self.queue_delay + noise
            
        elif self.current_state == self.STATE_JITTER:
            # æŠ–åŠ¨æ¨¡å¼ï¼šæ²¡æœ‰ç§¯å‹ï¼Œä½†æ–¹å·®å¾ˆå¤§
            self.queue_delay = max(0, self.queue_delay - 5)
            jitter = random.uniform(0, 100)
            rtt = self.base_rtt + jitter + noise
            
        return max(10, rtt), self.current_state

# ================= 3. ä¸»ç¨‹åºï¼šéªŒè¯ Online Learning =================

if __name__ == "__main__":
    TOTAL_STEPS = 1500
    sim = NetworkSimulator(TOTAL_STEPS)
    pacer = SmartTokenPacer(input_features=2, pred_len=10)
    pacer.set_scaler(mean=[4.0, 0.0], scale=[1.0, 1.0])
    
    history = {'real_rtt': [], 'pred_rtt': [], 'score': [], 'state': []}
    
    print("ğŸš€ Starting Simulation...")
    prev_log_rtt = 0
    
    for t in range(TOTAL_STEPS):
        real_rtt, state = sim.step()
        log_rtt = np.log1p(real_rtt)
        rtt_diff = log_rtt - prev_log_rtt
        prev_log_rtt = log_rtt
        
        score, pred_rtt = pacer.step([log_rtt, rtt_diff])
        
        history['real_rtt'].append(real_rtt)
        history['pred_rtt'].append(pred_rtt)
        history['score'].append(score)
        history['state'].append(state)

    # ================= å¯è§†åŒ–éƒ¨åˆ† (ä¿®æ”¹å) =================
    print("ğŸ“Š Generating Dual-Axis Plot...")
    
    fig, ax1 = plt.subplots(figsize=(14, 7))
    
    # 1. ç»˜åˆ¶èƒŒæ™¯çŠ¶æ€å¸¦ (Background Regions)
    states = np.array(history['state'])
    # è·å– Y è½´èŒƒå›´ä»¥ä¾¿å¡«å……æ•´ä¸ªé«˜åº¦
    y_max = max(max(history['real_rtt']), max(history['pred_rtt'])) * 1.1
    
    ax1.fill_between(range(TOTAL_STEPS), 0, y_max, where=(states==1), 
                     color='red', alpha=0.1, label='Congestion Zone')
    ax1.fill_between(range(TOTAL_STEPS), 0, y_max, where=(states==2), 
                     color='orange', alpha=0.1, label='Jitter Zone')

    # 2. å·¦è½´ (Left Axis): RTT
    ax1.set_xlabel('Time Step (Simulation)', fontsize=12)
    ax1.set_ylabel('RTT (ms)', color='tab:blue', fontsize=12)
    
    # çœŸå® RTT (åŠé€æ˜ï¼Œä½œä¸ºèƒŒæ™¯å‚è€ƒ)
    l1, = ax1.plot(history['real_rtt'], color='tab:blue', alpha=0.3, linewidth=1, label='Real RTT')
    # é¢„æµ‹ RTT (æ·±ç´«è‰²è™šçº¿ï¼Œå±•ç¤ºæ¨¡å‹è¿½è¸ªèƒ½åŠ›)
    l2, = ax1.plot(history['pred_rtt'], color='tab:purple', linestyle='--', linewidth=1.5, label='Pred RTT (LSTM)')
    
    ax1.tick_params(axis='y', labelcolor='tab:blue')
    ax1.set_ylim(0, y_max)

    # 3. å³è½´ (Right Axis): Health Score
    ax2 = ax1.twinx()  # å…±äº« X è½´
    ax2.set_ylabel('Health Score (0.0 - 1.0)', color='tab:red', fontsize=12)
    
    # å¥åº·åˆ† (çº¢è‰²ç²—çº¿ï¼Œé†’ç›®)
    l3, = ax2.plot(history['score'], color='tab:red', linewidth=2.5, label='Token Pacer Score')
    
    ax2.tick_params(axis='y', labelcolor='tab:red')
    ax2.set_ylim(-0.05, 1.1) # å›ºå®šèŒƒå›´
    
    # è¾…åŠ©çº¿ (0.5 åˆ†ç•Œçº¿)
    ax2.axhline(0.5, color='gray', linestyle=':', alpha=0.5)

    # 4. åˆå¹¶å›¾ä¾‹ (Legend)
    lines = [l1, l2, l3]
    labels = [l.get_label() for l in lines]
    # æ·»åŠ èƒŒæ™¯çŠ¶æ€çš„å›¾ä¾‹
    import matplotlib.patches as mpatches
    patch_cong = mpatches.Patch(color='red', alpha=0.1, label='Congestion Zone')
    patch_jitt = mpatches.Patch(color='orange', alpha=0.1, label='Jitter Zone')
    
    lines.extend([patch_cong, patch_jitt])
    labels.extend(['Congestion Zone', 'Jitter Zone'])
    
    ax1.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=5, frameon=False)
    
    plt.title("Smart Token Pacer: Real-time RTT Prediction vs. Health Score", y=1.1, fontsize=14)
    plt.tight_layout()
    plt.savefig("pacer_dual_axis.png", dpi=150)
    print("âœ… Plot saved to pacer_dual_axis.png")