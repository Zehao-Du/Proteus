#!/usr/bin/env python3
"""
Integrated A/B Experiment with Real vLLM

å°†æ¨¡æ‹Ÿç½‘ç»œä¸å®é™… vLLM ç»“åˆçš„ A/B å®éªŒï¼š

1. ä½¿ç”¨ multi_user_hint_server.py æ¨¡æ‹Ÿå¤šç”¨æˆ·ç½‘ç»œ
2. å®é™…è°ƒç”¨ vLLM ç”Ÿæˆ token
3. æ ¹æ®æ¨¡æ‹Ÿçš„ RTT è®¡ç®—"æœ‰æ•ˆæ¥æ”¶"çš„ token æ•°
4. å¯¹æ¯” Baseline vs Network-Aware çš„ ETPS

å®éªŒæµç¨‹ï¼š
1. å¯åŠ¨ multi_user_hint_server.py
2. å¯åŠ¨ vLLM (è®¾ç½® VLLM_HINT_SERVER_URL)
3. è¿è¡Œæœ¬è„šæœ¬è¿›è¡Œ A/B å®éªŒ
"""

import argparse
import json
import sys
import time
import threading
import requests
from dataclasses import dataclass
from typing import List, Dict, Optional
from collections import deque

import numpy as np


@dataclass
class UserSession:
    """ç”¨æˆ·ä¼šè¯"""
    user_id: int
    prompt: str
    tokens_generated: int = 0
    tokens_effective: int = 0
    tokens_wasted: int = 0
    start_time: float = 0
    end_time: float = 0
    avg_rtt: float = 0
    avg_health: float = 0


@dataclass
class ExperimentResult:
    """å®éªŒç»“æœ"""
    mode: str
    total_tokens_generated: int
    total_tokens_effective: int
    total_tokens_wasted: int
    duration: float
    etps: float
    user_sessions: List[UserSession]


class IntegratedExperiment:
    """é›†æˆå®éªŒ"""
    
    def __init__(
        self,
        vllm_url: str = "http://localhost:8000/v1",
        hint_server_url: str = "http://localhost:5000",
        total_budget: float = 100  # tokens/s
    ):
        self.vllm_url = vllm_url
        self.hint_server_url = hint_server_url
        self.total_budget = total_budget
        
        # æ¨¡å‹åç§°ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
        self.model_name = self._detect_model()
    
    def _detect_model(self) -> str:
        """æ£€æµ‹ vLLM æ¨¡å‹åç§°"""
        try:
            resp = requests.get(f"{self.vllm_url}/models", timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                if data.get("data"):
                    return data["data"][0]["id"]
        except:
            pass
        return "default"
    
    def _set_mode(self, mode: str):
        """è®¾ç½® Hint Server æ¨¡å¼"""
        try:
            resp = requests.post(f"{self.hint_server_url}/mode/{mode}", timeout=2)
            if resp.status_code == 200:
                print(f"âœ… Mode set to: {mode}")
                return True
        except Exception as e:
            print(f"âš ï¸ Failed to set mode: {e}")
        return False
    
    def _get_user_allocation(self, user_id: int) -> Dict:
        """è·å–ç”¨æˆ·çš„å½“å‰åˆ†é…ä¿¡æ¯"""
        try:
            resp = requests.get(f"{self.hint_server_url}/hint?user_id={user_id}", timeout=0.5)
            if resp.status_code == 200:
                return resp.json()
        except:
            pass
        return {"health": 1.0, "metrics": {"max_receive_rate": 50, "rtt": 100}}
    
    def _generate_tokens(
        self,
        prompt: str,
        max_tokens: int = 100,
        user_id: int = 1
    ) -> UserSession:
        """
        ç”Ÿæˆ token å¹¶è®¡ç®—æœ‰æ•ˆæ¥æ”¶æ•°ã€‚
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        - vLLM æŒ‰ health_factor æ§åˆ¶ç”Ÿæˆé€Ÿç‡
        - æˆ‘ä»¬æ ¹æ®æ¨¡æ‹Ÿçš„ RTT è®¡ç®—"æœ‰æ•ˆæ¥æ”¶"æ•°
        """
        session = UserSession(
            user_id=user_id,
            prompt=prompt[:50] + "..." if len(prompt) > 50 else prompt,
            start_time=time.time()
        )
        
        payload = {
            "model": self.model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": 0.7,
            "stream": True
        }
        
        rtt_samples = []
        health_samples = []
        
        try:
            response = requests.post(
                f"{self.vllm_url}/chat/completions",
                json=payload,
                stream=True,
                timeout=120
            )
            response.raise_for_status()
            
            for line in response.iter_lines():
                if not line:
                    continue
                
                if line.startswith(b"data: "):
                    data_str = line[6:].decode('utf-8')
                    if data_str == "[DONE]":
                        break
                    
                    try:
                        data = json.loads(data_str)
                        choices = data.get("choices", [])
                        if choices:
                            delta = choices[0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                session.tokens_generated += 1
                                
                                # è·å–å½“å‰ç”¨æˆ·çš„ç½‘ç»œçŠ¶æ€
                                alloc = self._get_user_allocation(user_id)
                                rtt = alloc.get("metrics", {}).get("rtt", 100)
                                health = alloc.get("health", 1.0)
                                max_rate = alloc.get("metrics", {}).get("max_receive_rate", 50)
                                
                                rtt_samples.append(rtt)
                                health_samples.append(health)
                                
                                # --- [å‘é€é€Ÿç‡ vs ç½‘ç»œå®¹é‡ æ¨¡å‹] ---
                                # ç‰©ç†åŸç†ï¼š
                                # 1. ç½‘ç»œå®¹é‡ = max_receive_rate (tokens/s)ï¼Œç”± RTT å†³å®š
                                # 2. å‘é€é€Ÿç‡ = å½“å‰ token ç”Ÿæˆé€Ÿç‡
                                # 3. å¦‚æœ å‘é€ > å®¹é‡ï¼Œç¼“å†²åŒºæº¢å‡ºï¼Œä¸¢åŒ…
                                # 4. å¦‚æœ å‘é€ â‰¤ å®¹é‡ï¼Œå‡ ä¹ä¸ä¸¢åŒ…
                                #
                                # max_receive_rate è®¡ç®—ï¼šRTT ä½ â†’ å®¹é‡å¤§
                                # capacity = 500 / max(rtt, 10) tokens/s
                                # RTT=20ms  â†’ 25 tokens/s
                                # RTT=100ms â†’ 5 tokens/s
                                # RTT=400ms â†’ 1.25 tokens/s
                                
                                network_capacity = 500.0 / max(rtt, 10)  # tokens/s
                                
                                # è®¡ç®—å½“å‰å‘é€é€Ÿç‡
                                elapsed = time.time() - session.start_time
                                if elapsed > 0.1:
                                    send_rate = session.tokens_generated / elapsed
                                else:
                                    send_rate = 50  # é»˜è®¤ä¼°è®¡
                                
                                # ä¸¢åŒ…ç‡ = max(0, (å‘é€ - å®¹é‡) / å‘é€)
                                if send_rate <= network_capacity:
                                    # ç½‘ç»œèƒ½æ‰¿å—ï¼Œä¸ä¸¢åŒ…
                                    session.tokens_effective += 1
                                else:
                                    # ç½‘ç»œè¿‡è½½ï¼ŒæŒ‰æ¯”ä¾‹ä¸¢åŒ…
                                    keep_rate = network_capacity / send_rate
                                    if not hasattr(session, '_effective_accumulator'):
                                        session._effective_accumulator = 0.0
                                    session._effective_accumulator += keep_rate
                                    if session._effective_accumulator >= 1.0:
                                        session.tokens_effective += 1
                                        session._effective_accumulator -= 1.0
                                    else:
                                        session.tokens_wasted += 1
                                # --- [END å‘é€é€Ÿç‡æ¨¡å‹] ---
                                
                                # æ‰“å°è¿›åº¦
                                sys.stdout.write(content)
                                sys.stdout.flush()
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            print(f"\nâŒ Error: {e}")
        
        session.end_time = time.time()
        session.avg_rtt = np.mean(rtt_samples) if rtt_samples else 0
        session.avg_health = np.mean(health_samples) if health_samples else 1.0
        
        return session
    
    def run_group(
        self,
        mode: str,
        prompts: List[str],
        max_tokens: int = 100,
        user_ids: List[int] = [1, 2]
    ) -> ExperimentResult:
        """è¿è¡Œä¸€ç»„å®éªŒ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Running {mode.upper()} Group (CONCURRENT)")
        print(f"{'='*60}")
        
        # è®¾ç½®æ¨¡å¼
        self._set_mode(mode)
        time.sleep(0.5)  # ç­‰å¾…æ¨¡å¼åˆ‡æ¢ç”Ÿæ•ˆ
        
        sessions = []
        results_lock = threading.Lock()
        start_time = time.time()
        
        def run_user_session(prompt, user_id):
            """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œç”¨æˆ·ä¼šè¯"""
            print(f"\n[User {user_id}] Starting: {prompt[:50]}...")
            session = self._generate_tokens(prompt, max_tokens, user_id)
            with results_lock:
                sessions.append(session)
            print(f"\nâœ… User {user_id}: Generated={session.tokens_generated}, "
                  f"Effective={session.tokens_effective}, "
                  f"Wasted={session.tokens_wasted}")
        
        # å¹¶å‘è¿è¡Œæ‰€æœ‰ç”¨æˆ·çš„è¯·æ±‚
        threads = []
        for prompt, user_id in zip(prompts, user_ids):
            t = threading.Thread(target=run_user_session, args=(prompt, user_id))
            threads.append(t)
            t.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for t in threads:
            t.join()
        
        end_time = time.time()
        duration = end_time - start_time
        
        # æ±‡æ€»ç»“æœ
        total_generated = sum(s.tokens_generated for s in sessions)
        total_effective = sum(s.tokens_effective for s in sessions)
        total_wasted = sum(s.tokens_wasted for s in sessions)
        etps = total_effective / duration if duration > 0 else 0
        
        return ExperimentResult(
            mode=mode,
            total_tokens_generated=total_generated,
            total_tokens_effective=total_effective,
            total_tokens_wasted=total_wasted,
            duration=duration,
            etps=etps,
            user_sessions=sessions
        )
    
    def run_experiment(
        self,
        prompts: List[str] = None,
        max_tokens: int = 200,  # å¢åŠ  token æ•°ï¼Œè®©è¯·æ±‚æœ‰æ›´é•¿çš„å¹¶å‘æ—¶é—´
        user_ids: List[int] = [1, 2]
    ):
        """è¿è¡Œå®Œæ•´ A/B å®éªŒ"""
        if prompts is None:
            # ä½¿ç”¨æ›´é•¿çš„ promptsï¼Œç¡®ä¿ä¸¤ä¸ªè¯·æ±‚æœ‰è¶³å¤Ÿçš„é‡å æ—¶é—´
            prompts = [
                "Write a very detailed and comprehensive explanation of how neural networks learn through backpropagation, including the mathematical foundations and practical applications.",
                "Explain in great detail the concept of gradient descent and all its variants in machine learning, with examples and comparisons."
            ]
        
        print("\n" + "ğŸš€" * 20)
        print("    INTEGRATED A/B EXPERIMENT")
        print("ğŸš€" * 20)
        print(f"\nğŸ“Š Configuration:")
        print(f"   vLLM URL: {self.vllm_url}")
        print(f"   Hint Server: {self.hint_server_url}")
        print(f"   Model: {self.model_name}")
        print(f"   Max Tokens: {max_tokens}")
        print(f"   Users: {user_ids}")
        
        # è¿è¡Œ Baseline ç»„
        baseline_result = self.run_group(
            mode="baseline",
            prompts=prompts,
            max_tokens=max_tokens,
            user_ids=user_ids
        )
        
        time.sleep(2)  # ç»„é—´é—´éš”
        
        # è¿è¡Œ Network-Aware ç»„
        network_aware_result = self.run_group(
            mode="network_aware",
            prompts=prompts,
            max_tokens=max_tokens,
            user_ids=user_ids
        )
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        self._print_comparison(baseline_result, network_aware_result)
        
        return baseline_result, network_aware_result
    
    def _print_comparison(self, baseline: ExperimentResult, network_aware: ExperimentResult):
        """æ‰“å°å¯¹æ¯”ç»“æœ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š EXPERIMENT RESULTS COMPARISON")
        print("=" * 60)
        
        print(f"\nğŸ”´ BASELINE (Equal Allocation):")
        print(f"   Total Generated:  {baseline.total_tokens_generated}")
        print(f"   Total Effective:  {baseline.total_tokens_effective}")
        print(f"   Total Wasted:     {baseline.total_tokens_wasted} "
              f"({baseline.total_tokens_wasted/max(1,baseline.total_tokens_generated)*100:.1f}%)")
        print(f"   Duration:         {baseline.duration:.2f}s")
        print(f"   ETPS:             {baseline.etps:.2f}")
        for s in baseline.user_sessions:
            print(f"   â””â”€ User {s.user_id}: gen={s.tokens_generated}, eff={s.tokens_effective}, "
                  f"rtt={s.avg_rtt:.0f}ms")
        
        print(f"\nğŸŸ¢ NETWORK-AWARE (Health-Based Allocation):")
        print(f"   Total Generated:  {network_aware.total_tokens_generated}")
        print(f"   Total Effective:  {network_aware.total_tokens_effective}")
        print(f"   Total Wasted:     {network_aware.total_tokens_wasted} "
              f"({network_aware.total_tokens_wasted/max(1,network_aware.total_tokens_generated)*100:.1f}%)")
        print(f"   Duration:         {network_aware.duration:.2f}s")
        print(f"   ETPS:             {network_aware.etps:.2f}")
        for s in network_aware.user_sessions:
            print(f"   â””â”€ User {s.user_id}: gen={s.tokens_generated}, eff={s.tokens_effective}, "
                  f"rtt={s.avg_rtt:.0f}ms, health={s.avg_health:.2f}")
        
        # è®¡ç®—æå‡
        if baseline.etps > 0:
            improvement = (network_aware.etps - baseline.etps) / baseline.etps * 100
        else:
            improvement = 0
        
        waste_baseline = baseline.total_tokens_wasted
        waste_network = network_aware.total_tokens_wasted
        waste_reduction = (waste_baseline - waste_network) / max(1, waste_baseline) * 100
        
        print(f"\nğŸ“ˆ IMPROVEMENT:")
        print(f"   ETPS Improvement:   {improvement:+.2f}%")
        print(f"   Waste Reduction:    {waste_reduction:+.2f}%")
        
        if improvement > 0:
            print(f"\n   âœ… Network-Aware scheduling outperforms Baseline!")
        else:
            print(f"\n   âš ï¸ Results inconclusive")


def main():
    parser = argparse.ArgumentParser(description="Integrated A/B Experiment")
    parser.add_argument("--vllm-url", default="http://localhost:8000/v1")
    parser.add_argument("--hint-url", default="http://localhost:5000")
    parser.add_argument("--max-tokens", type=int, default=200)
    parser.add_argument("--num-users", type=int, default=8)  # å¢åŠ åˆ° 8 ä¸ªç”¨æˆ·ï¼
    args = parser.parse_args()
    
    # ç”Ÿæˆå¤šä¸ªç”¨æˆ·çš„ prompts
    base_prompts = [
        "Write a detailed explanation of deep learning architectures.",
        "Explain optimization algorithms in machine learning.",
        "Describe the process of training large language models.",
        "Write about the history of artificial intelligence.",
        "Explain how neural networks learn patterns from data.",
        "Describe the transformer architecture in detail.",
        "Write about reinforcement learning algorithms.",
        "Explain the concept of attention mechanisms in AI.",
    ]
    
    # ç”¨æˆ· ID åˆ†é…ï¼š1-4 ç½‘ç»œå·®ï¼›5-8 ç½‘ç»œå¥½ï¼ˆéœ€è¦æ›´æ–° hint serverï¼‰
    user_ids = list(range(1, args.num_users + 1))
    prompts = base_prompts[:args.num_users]
    
    experiment = IntegratedExperiment(
        vllm_url=args.vllm_url,
        hint_server_url=args.hint_url
    )
    
    experiment.run_experiment(
        prompts=prompts,
        max_tokens=args.max_tokens,
        user_ids=user_ids
    )


if __name__ == "__main__":
    main()

