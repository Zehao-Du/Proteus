#!/usr/bin/env python3
"""
ğŸš€ MASSIVE A/B EXPERIMENT - 8192 Users with TIME LIMIT!

æ¨¡æ‹Ÿ 8192 ä¸ªç”¨æˆ·åŒæ—¶è¯·æ±‚ vLLMï¼ŒéªŒè¯ç½‘ç»œæ„ŸçŸ¥è°ƒåº¦çš„æ•ˆæœã€‚

æ ¸å¿ƒæœºåˆ¶ï¼š
- è®¾ç½®å…¨å±€æ—¶é—´é™åˆ¶ï¼ˆå¦‚ 30 ç§’ï¼‰
- é«˜ä¼˜å…ˆçº§ç”¨æˆ·å…ˆå®Œæˆ â†’ æˆåŠŸ
- ä½ä¼˜å…ˆçº§ç”¨æˆ·å¯èƒ½è¶…æ—¶ â†’ å¤±è´¥
- Network-aware è°ƒåº¦è®©é«˜å¥åº·åº¦ç”¨æˆ·ä¼˜å…ˆè·å¾— GPU

ç”¨æˆ·ç½‘ç»œåˆ†å¸ƒï¼š
- 20% å¾ˆå·® (RTT 400-500ms, health ~0.1)
- 30% å·® (RTT 200-400ms, health ~0.3)
- 30% å¥½ (RTT 50-200ms, health ~0.6)
- 20% å¾ˆå¥½ (RTT 10-50ms, health ~0.9)
"""

import argparse
import asyncio
import aiohttp
import json
import time
import numpy as np
from dataclasses import dataclass, field
from typing import List, Dict
from collections import defaultdict
import sys


@dataclass
class UserProfile:
    """ç”¨æˆ·é…ç½®"""
    user_id: int
    rtt: float  # ms
    health: float  # 0.0-1.0
    category: str  # 'very_bad', 'bad', 'good', 'very_good'
    patience: float = 0  # ç”¨æˆ·è€å¿ƒå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…æ—¶å°±æ”¾å¼ƒ


@dataclass
class RequestResult:
    """è¯·æ±‚ç»“æœ"""
    user_id: int
    tokens_generated: int = 0
    tokens_effective: int = 0
    start_time: float = 0
    end_time: float = 0
    rtt: float = 0
    health: float = 0
    completed: bool = False  # æ˜¯å¦å®Œæˆ
    timeout: bool = False    # æ˜¯å¦è¶…æ—¶


def generate_user_profiles(num_users: int = 8192, time_limit: float = 30.0) -> List[UserProfile]:
    """ç”Ÿæˆç”¨æˆ·é…ç½® - ä½¿ç”¨æ­£æ€åˆ†å¸ƒï¼ˆæœ‰é•¿å°¾ï¼‰
    
    RTT åˆ†å¸ƒï¼š
    - å‡å€¼ 400msï¼Œæ ‡å‡†å·® 1000ms
    - æˆªæ–­åˆ° [0, 800000] ms èŒƒå›´ï¼ˆæ¨¡æ‹Ÿæç«¯æƒ…å†µï¼šæœ‰äºº RTT å¾ˆå°ï¼Œæœ‰äººå¾ˆå¤§ï¼‰
    - å½¢æˆé•¿å°¾åˆ†å¸ƒï¼šå¤§å¤šæ•°ç”¨æˆ·ç½‘ç»œæ­£å¸¸ï¼Œå°‘æ•°ç”¨æˆ·ç½‘ç»œå¾ˆå·®
    
    å¥åº·åº¦è®¡ç®—ï¼š
    - health = exp(-RTT / 500)
    - RTT è¶Šé«˜ï¼Œå¥åº·åº¦è¶Šä½
    - ä½¿ç”¨ 500 è€Œä¸æ˜¯ 150ï¼Œä»¥é€‚é…æ–°çš„ RTT åˆ†å¸ƒ (loc=400, scale=1000)
    
    è€å¿ƒå€¼ï¼š
    - patience = time_limit Ã— (0.3 + 0.7 Ã— health)
    - ç½‘ç»œå¥½çš„ç”¨æˆ·æ„¿æ„ç­‰æ›´ä¹…
    """
    profiles = []
    
    # ä½¿ç”¨æ­£æ€åˆ†å¸ƒç”Ÿæˆ RTTï¼ˆå‡å€¼ 400msï¼Œæ ‡å‡†å·® 1000msï¼‰
    rtts = np.random.normal(loc=400, scale=1000, size=num_users)
    
    # æˆªæ–­åˆ°åˆç†èŒƒå›´ [0, 800000] msï¼ˆæ¨¡æ‹Ÿæç«¯æƒ…å†µï¼‰
    rtts = np.clip(rtts, 0, 800000)
    
    for user_id, rtt in enumerate(rtts, start=1):
        # æ ¹æ® RTT è®¡ç®—å¥åº·åº¦ï¼šhealth = exp(-RTT / 500)
        # ä½¿ç”¨ 500 è€Œä¸æ˜¯ 150ï¼Œä»¥é€‚é…æ–°çš„ RTT åˆ†å¸ƒ (loc=400, scale=1000)
        health = np.exp(-rtt / 500.0)
        
        # æ ¹æ® RTT åˆ†ç±»
        if rtt >= 400:
            category = 'very_bad'
        elif rtt >= 200:
            category = 'bad'
        elif rtt >= 80:
            category = 'good'
        else:
            category = 'very_good'
        
        # è€å¿ƒå€¼ï¼šç½‘ç»œå¥½çš„ç”¨æˆ·æ„¿æ„ç­‰æ›´ä¹…
        patience = time_limit * (0.3 + 0.7 * health)
        
        profiles.append(UserProfile(
            user_id=user_id,
            rtt=rtt,
            health=health,
            category=category,
            patience=patience
        ))
    
    # æ‰“ä¹±é¡ºåº
    np.random.shuffle(profiles)
    return profiles


class MassiveExperiment:
    """å¤§è§„æ¨¡å®éªŒ - å¸¦æ—¶é—´é™åˆ¶çš„ç«äº‰"""
    
    def __init__(
        self,
        vllm_url: str = "http://localhost:8000/v1",
        num_users: int = 8192,
        max_tokens: int = 50,
        concurrency: int = 256,  # åŒæ—¶å‘é€çš„è¯·æ±‚æ•°
        time_limit: float = 30.0,  # å…¨å±€æ—¶é—´é™åˆ¶ï¼ˆç§’ï¼‰
    ):
        self.vllm_url = vllm_url
        self.num_users = num_users
        self.max_tokens = max_tokens
        self.concurrency = concurrency
        self.time_limit = time_limit
        self.model_name = None
        self.experiment_start_time = 0  # å®éªŒå¼€å§‹æ—¶é—´
        
        # ç”Ÿæˆç”¨æˆ·é…ç½®
        self.user_profiles = generate_user_profiles(num_users, time_limit)
        
        # ç»Ÿè®¡
        self.results: List[RequestResult] = []
        
    async def detect_model(self, session: aiohttp.ClientSession) -> str:
        """æ£€æµ‹æ¨¡å‹åç§°"""
        try:
            async with session.get(f"{self.vllm_url}/models") as resp:
                if resp.status == 200:
                    data = await resp.json()
                    models = data.get("data", [])
                    if models:
                        return models[0].get("id", "unknown")
        except:
            pass
        return "unknown"
    
    async def send_request(
        self,
        session: aiohttp.ClientSession,
        profile: UserProfile,
        semaphore: asyncio.Semaphore,
        mode: str,
    ) -> RequestResult:
        """å‘é€å•ä¸ªè¯·æ±‚ - å¸¦ç”¨æˆ·è€å¿ƒè¶…æ—¶"""
        result = RequestResult(
            user_id=profile.user_id,
            rtt=profile.rtt,
            health=profile.health,
            start_time=time.time(),
        )
        
        prompt = f"User {profile.user_id}: Write a brief story about AI."
        
        payload = {
            "model": self.model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": self.max_tokens,
            "stream": True,
        }
        
        # ç”¨æˆ·è€å¿ƒè¶…æ—¶ï¼šç½‘ç»œå·®çš„ç”¨æˆ·æ›´å®¹æ˜“æ”¾å¼ƒ
        user_timeout = profile.patience
        
        async with semaphore:
            try:
                async with session.post(
                    f"{self.vllm_url}/chat/completions",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=user_timeout),
                ) as resp:
                    if resp.status != 200:
                        return result
                    
                    effective_accumulator = 0.0
                    first_token_time = None
                    
                    async for line in resp.content:
                        # æ£€æŸ¥å…¨å±€æ—¶é—´é™åˆ¶
                        if time.time() - self.experiment_start_time > self.time_limit:
                            result.timeout = True
                            break
                        
                        if not line:
                            continue
                        
                        line_str = line.decode('utf-8').strip()
                        if not line_str.startswith("data: "):
                            continue
                        
                        data_str = line_str[6:]
                        if data_str == "[DONE]":
                            result.completed = True
                            break
                        
                        try:
                            data = json.loads(data_str)
                            choices = data.get("choices", [])
                            if choices:
                                delta = choices[0].get("delta", {})
                                if delta.get("content"):
                                    if first_token_time is None:
                                        first_token_time = time.time()
                                    
                                    result.tokens_generated += 1
                                    
                                    # è®¡ç®—æœ‰æ•ˆç‡ï¼ˆåŸºäºç½‘ç»œå®¹é‡æ¨¡å‹ï¼‰
                                    elapsed = time.time() - result.start_time
                                    if elapsed > 0.1:
                                        send_rate = result.tokens_generated / elapsed
                                        network_capacity = 500.0 / max(profile.rtt, 10)
                                        
                                        if send_rate <= network_capacity:
                                            result.tokens_effective += 1
                                        else:
                                            keep_rate = network_capacity / send_rate
                                            effective_accumulator += keep_rate
                                            if effective_accumulator >= 1.0:
                                                result.tokens_effective += 1
                                                effective_accumulator -= 1.0
                                    else:
                                        result.tokens_effective += 1
                        except json.JSONDecodeError:
                            continue
                            
            except asyncio.TimeoutError:
                result.timeout = True
            except Exception as e:
                pass
        
        result.end_time = time.time()
        return result
    
    async def run_experiment(self, mode: str) -> Dict:
        """è¿è¡Œå®éªŒ - å¸¦æ—¶é—´é™åˆ¶çš„ç«äº‰"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ Running {mode.upper()} - {self.num_users} Users")
        print(f"{'='*60}")
        
        connector = aiohttp.TCPConnector(limit=self.concurrency)
        async with aiohttp.ClientSession(connector=connector) as session:
            # æ£€æµ‹æ¨¡å‹
            if not self.model_name:
                self.model_name = await self.detect_model(session)
                print(f"ğŸ“¦ Model: {self.model_name}")
            
            print(f"ğŸ”¢ Users: {self.num_users}")
            print(f"ğŸ¯ Concurrency: {self.concurrency}")
            print(f"ğŸ“ Max tokens: {self.max_tokens}")
            print(f"â±ï¸  Time limit: {self.time_limit}s")
            
            # è®¾ç½®æ¨¡å¼
            try:
                async with session.post(f"http://localhost:5000/mode/{mode}") as resp:
                    if resp.status == 200:
                        print(f"âœ… Mode set to: {mode}")
            except:
                print(f"âš ï¸ Could not set mode (hint server may not be running)")
            
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(self.concurrency)
            
            # è®¾ç½®å®éªŒå¼€å§‹æ—¶é—´ï¼ˆå…¨å±€æ—¶é—´é™åˆ¶çš„èµ·ç‚¹ï¼‰
            self.experiment_start_time = time.time()
            start_time = self.experiment_start_time
            
            tasks = [
                self.send_request(session, profile, semaphore, mode)
                for profile in self.user_profiles
            ]
            
            # ä½¿ç”¨è¿›åº¦æ˜¾ç¤º
            print(f"\nâ³ Sending {len(tasks)} requests (time limit: {self.time_limit}s)...")
            
            # ä½¿ç”¨ asyncio.wait è€Œä¸æ˜¯ gatherï¼Œè¿™æ ·å¯ä»¥è®¾ç½®è¶…æ—¶
            try:
                results = await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=self.time_limit + 5  # é¢å¤–5ç§’ç”¨äºæ¸…ç†
                )
            except asyncio.TimeoutError:
                print(f"âš ï¸ Global timeout reached!")
                results = []
            
            end_time = time.time()
            duration = min(end_time - start_time, self.time_limit)
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        valid_results = [r for r in results if isinstance(r, RequestResult)]
        
        # ç»Ÿè®¡ç»“æœ
        total_generated = sum(r.tokens_generated for r in valid_results)
        total_effective = sum(r.tokens_effective for r in valid_results)
        total_wasted = total_generated - total_effective
        total_completed = sum(1 for r in valid_results if r.completed)
        total_timeout = sum(1 for r in valid_results if r.timeout)
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_stats = defaultdict(lambda: {"gen": 0, "eff": 0, "count": 0, "completed": 0, "timeout": 0})
        for result, profile in zip(valid_results, self.user_profiles):
            cat = profile.category
            category_stats[cat]["gen"] += result.tokens_generated
            category_stats[cat]["eff"] += result.tokens_effective
            category_stats[cat]["count"] += 1
            if result.completed:
                category_stats[cat]["completed"] += 1
            if result.timeout:
                category_stats[cat]["timeout"] += 1
        
        stats = {
            "mode": mode,
            "num_users": self.num_users,
            "duration": duration,
            "total_generated": total_generated,
            "total_effective": total_effective,
            "total_wasted": total_wasted,
            "waste_rate": total_wasted / max(total_generated, 1) * 100,
            "etps": total_effective / duration if duration > 0 else 0,
            "throughput": total_generated / duration if duration > 0 else 0,
            "total_completed": total_completed,
            "total_timeout": total_timeout,
            "completion_rate": total_completed / max(len(valid_results), 1) * 100,
            "category_stats": dict(category_stats),
        }
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Results:")
        print(f"   Duration: {duration:.2f}s")
        print(f"   Total Generated: {total_generated}")
        print(f"   Total Effective: {total_effective}")
        print(f"   Waste Rate: {stats['waste_rate']:.1f}%")
        print(f"   ETPS: {stats['etps']:.2f}")
        print(f"   Throughput: {stats['throughput']:.2f} tokens/s")
        print(f"   Completed: {total_completed}/{len(valid_results)} ({stats['completion_rate']:.1f}%)")
        print(f"   Timeout: {total_timeout}")
        
        print(f"\n   By Category:")
        for cat in ['very_bad', 'bad', 'good', 'very_good']:
            s = category_stats[cat]
            if s["count"] > 0:
                eff_rate = s["eff"] / max(s["gen"], 1) * 100
                comp_rate = s["completed"] / s["count"] * 100
                print(f"   â””â”€ {cat:10s}: users={s['count']:4d}, gen={s['gen']:5d}, eff={s['eff']:5d} ({eff_rate:.1f}%), completed={s['completed']} ({comp_rate:.1f}%)")
        
        return stats
    
    async def run_ab_experiment(self):
        """è¿è¡Œ A/B å®éªŒ - æ—¶é—´é™åˆ¶ç«äº‰"""
        print("\n" + "ğŸš€" * 30)
        print(f"     MASSIVE A/B EXPERIMENT - {self.num_users} USERS")
        print(f"     TIME LIMIT: {self.time_limit} SECONDS")
        print("ğŸš€" * 30)
        
        # é‡æ–°ç”Ÿæˆç”¨æˆ·é…ç½®ï¼ˆç¡®ä¿ä¸¤æ¬¡å®éªŒç”¨åŒæ ·çš„ç”¨æˆ·ï¼‰
        self.user_profiles = generate_user_profiles(self.num_users, self.time_limit)
        
        # Baseline
        baseline = await self.run_experiment("baseline")
        
        await asyncio.sleep(3)
        
        # é‡æ–°ç”Ÿæˆç›¸åŒçš„ç”¨æˆ·é…ç½®
        np.random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯é‡å¤
        self.user_profiles = generate_user_profiles(self.num_users, self.time_limit)
        
        # Network-Aware
        network_aware = await self.run_experiment("network_aware")
        
        # å¯¹æ¯”
        print("\n" + "=" * 60)
        print("ğŸ“Š COMPARISON")
        print("=" * 60)
        
        print(f"\nğŸ”´ BASELINE:")
        print(f"   ETPS: {baseline['etps']:.2f}")
        print(f"   Waste: {baseline['waste_rate']:.1f}%")
        print(f"   Completed: {baseline['total_completed']}/{self.num_users} ({baseline['completion_rate']:.1f}%)")
        
        print(f"\nğŸŸ¢ NETWORK-AWARE:")
        print(f"   ETPS: {network_aware['etps']:.2f}")
        print(f"   Waste: {network_aware['waste_rate']:.1f}%")
        print(f"   Completed: {network_aware['total_completed']}/{self.num_users} ({network_aware['completion_rate']:.1f}%)")
        
        improvement = (network_aware['etps'] - baseline['etps']) / max(baseline['etps'], 1) * 100
        waste_reduction = baseline['waste_rate'] - network_aware['waste_rate']
        completion_improvement = network_aware['completion_rate'] - baseline['completion_rate']
        
        print(f"\nğŸ“ˆ IMPROVEMENT:")
        print(f"   ETPS: {improvement:+.2f}%")
        print(f"   Waste Reduction: {waste_reduction:+.2f}%")
        print(f"   Completion Rate: {completion_improvement:+.2f}%")
        
        # æŒ‰ç±»åˆ«å¯¹æ¯”
        print(f"\nğŸ“Š BY CATEGORY COMPARISON:")
        for cat in ['very_bad', 'bad', 'good', 'very_good']:
            b = baseline['category_stats'].get(cat, {})
            n = network_aware['category_stats'].get(cat, {})
            if b and n:
                b_comp = b.get('completed', 0) / max(b.get('count', 1), 1) * 100
                n_comp = n.get('completed', 0) / max(n.get('count', 1), 1) * 100
                print(f"   â””â”€ {cat:10s}: Baseline {b_comp:.1f}% â†’ Network-Aware {n_comp:.1f}% ({n_comp - b_comp:+.1f}%)")
        
        if improvement > 5:
            print(f"\n   ğŸ‰ Network-Aware scheduling wins with {improvement:.1f}% ETPS improvement!")
        elif improvement > 0:
            print(f"\n   âœ… Network-Aware scheduling shows modest improvement")
        else:
            print(f"\n   âš ï¸ Results inconclusive - try reducing max-num-seqs")


async def main():
    parser = argparse.ArgumentParser(description="Massive A/B Experiment with Time Limit")
    parser.add_argument("--vllm-url", default="http://localhost:8000/v1")
    parser.add_argument("--num-users", type=int, default=8192)
    parser.add_argument("--max-tokens", type=int, default=50)
    parser.add_argument("--concurrency", type=int, default=256)
    parser.add_argument("--time-limit", type=float, default=30.0, 
                        help="Time limit in seconds for each experiment run")
    args = parser.parse_args()
    
    experiment = MassiveExperiment(
        vllm_url=args.vllm_url,
        num_users=args.num_users,
        max_tokens=args.max_tokens,
        concurrency=args.concurrency,
        time_limit=args.time_limit,
    )
    
    await experiment.run_ab_experiment()


if __name__ == "__main__":
    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
    asyncio.run(main())

